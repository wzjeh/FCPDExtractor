{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30dcbcd6",
   "metadata": {},
   "source": [
    "# 🔬 OSSExtractor 表面合成参数提取工具 - 调试版本\n",
    "\n",
    "本notebook允许您逐步调试OSSExtractor的每个处理步骤，查看中间结果并优化参数。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29deb780",
   "metadata": {},
   "source": [
    "## 📦 导入必要的库和模块\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e4e064e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhaowenyuan/miniconda3/envs/ossextractor/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 所有模块导入成功！\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# 添加模块路径\n",
    "sys.path.append('Text Parser')\n",
    "sys.path.append('Text Extraction')\n",
    "\n",
    "# 导入统一的处理模块\n",
    "from PDF_Unified_Processor import PDFUnifiedProcessor, save_contents_to_specific_folders\n",
    "from TXT_Processing import process_text_file_for_processing\n",
    "from Embedding_and_Similarity import process_text_file_for_embedding\n",
    "from Unified_Text_Processor import (\n",
    "    process_text_file_for_filter,\n",
    "    process_text_file_for_abstract,\n",
    "    process_text_file_for_summerized,\n",
    "    process_text_file_for_filter_meta_llama,\n",
    "    process_text_file_for_abstract_meta_llama,\n",
    "    process_text_file_for_summerized_meta_llama_strict\n",
    ")\n",
    "\n",
    "print(\"✅ 所有模块导入成功！\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195375cc",
   "metadata": {},
   "source": [
    "## 🔄 处理流程说明\n",
    "\n",
    "**OSSExtractor的完整处理流程：**\n",
    "\n",
    "1. **PDF转文本** → 原始文本文件\n",
    "2. **文本预处理** → 段落分割和过滤\n",
    "3. **嵌入相似度筛选** → 从所有段落中选出最相关的N个段落\n",
    "4. **LLM内容过滤** → 从相似度筛选的段落中进一步筛选\n",
    "5. **抽象和总结** → 生成最终的结构化参数\n",
    "\n",
    "**段落数量变化示例：**\n",
    "- 原始文本: 100+ 段落\n",
    "- 预处理后: 50+ 段落  \n",
    "- 嵌入筛选后: 20 段落 (最相关的)\n",
    "- LLM过滤后: 10 段落 (最符合要求的)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87aff02e",
   "metadata": {},
   "source": [
    "## 🔧 配置参数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a93a1594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 将处理 1 个PDF文件:\n",
      "📁 主输出目录已设置为: /Users/zhaowenyuan/Projects/FCPDExtractor/Data/output\n",
      "----------------------------------------\n",
      "  1. 正在处理: 101021acsoprd7b00291.pdf\n",
      "     -> 将输出到: /Users/zhaowenyuan/Projects/FCPDExtractor/Data/output/101021acsoprd7b00291\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 配置要处理的PDF文件\n",
    "pdf_files = [\n",
    "    '/Users/zhaowenyuan/Projects/FCPDExtractor/Data/papers/101021acsoprd7b00291.pdf',\n",
    "    # 如果有更多文件，可以加在这里\n",
    "    # '/Users/zhaowenyuan/Projects/FCPDExtractor/Data/papers/another_paper.pdf',\n",
    "]\n",
    "\n",
    "# 定义基础的数据目录\n",
    "base_data_dir = '/Users/zhaowenyuan/Projects/FCPDExtractor/Data'\n",
    "\n",
    "# 1. 在Data目录下，定义一个名为 'output' 的主输出文件夹路径\n",
    "main_output_dir = os.path.join(base_data_dir, 'output')\n",
    "\n",
    "# 2. 创建 'output' 文件夹 (如果它不存在的话)\n",
    "# exist_ok=True 表示如果文件夹已存在，则不会报错\n",
    "os.makedirs(main_output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"📄 将处理 {len(pdf_files)} 个PDF文件:\")\n",
    "print(f\"📁 主输出目录已设置为: {main_output_dir}\")\n",
    "print(\"-\" * 40) # 打印分割线\n",
    "\n",
    "# 遍历每一个要处理的PDF文件\n",
    "for i, pdf_path in enumerate(pdf_files, 1):\n",
    "    \n",
    "    # 3. 从完整路径中获取PDF的文件名 (例如: 'd2cp03073j.pdf')\n",
    "    pdf_filename = os.path.basename(pdf_path)\n",
    "    \n",
    "    # 4. 去掉.pdf扩展名，创建文件夹名 (例如: 'd2cp03073j')\n",
    "    folder_name = os.path.splitext(pdf_filename)[0]\n",
    "    \n",
    "    # 5. 拼接出这个PDF专属的输出文件夹的完整路径\n",
    "    specific_output_dir = os.path.join(main_output_dir, folder_name)\n",
    "    \n",
    "    # 6. 创建这个专属的文件夹\n",
    "    os.makedirs(specific_output_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"  {i}. 正在处理: {pdf_filename}\")\n",
    "    print(f\"     -> 将输出到: {specific_output_dir}\")\n",
    "\n",
    "    # --- 在这里接上你后续的处理逻辑 ---\n",
    "    # 例如，你之后所有保存文件的操作，都应该使用 `specific_output_dir` 作为路径\n",
    "    # processed_text_path = os.path.join(specific_output_dir, 'Processed_text.txt')\n",
    "    # with open(processed_text_path, 'w') as f:\n",
    "    #     f.write(\"这里是处理后的文本\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4eb3a6",
   "metadata": {},
   "source": [
    "## 📄 步骤 1: PDF转文本处理\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a110213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 步骤 1/5: PDF转文本处理...\n",
      "==================================================\n",
      "✅ PDF转文本完成！生成了 1 个文本文件:\n",
      "  1. /Users/zhaowenyuan/Projects/FCPDExtractor/Data/output/101021acsoprd7b00291/101021acsoprd7b00291.txt\n",
      "     📊 行数: 731\n",
      "     📏 文件大小: 33175 bytes\n"
     ]
    }
   ],
   "source": [
    "print(\"🚀 步骤 1/5: PDF转文本处理...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 使用统一的PDF处理模块\n",
    "processor = PDFUnifiedProcessor()\n",
    "\n",
    "# 执行PDF转文本\n",
    "output_files = save_contents_to_specific_folders(pdf_files, main_output_dir)\n",
    "\n",
    "print(f\"✅ PDF转文本完成！生成了 {len(output_files)} 个文本文件:\")\n",
    "for i, file in enumerate(output_files, 1):\n",
    "    print(f\"  {i}. {file}\")\n",
    "    \n",
    "    # 显示文件大小和行数\n",
    "    if os.path.exists(file):\n",
    "        with open(file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            lines = f.readlines()\n",
    "            print(f\"     📊 行数: {len(lines)}\")\n",
    "            print(f\"     📏 文件大小: {os.path.getsize(file)} bytes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d163864",
   "metadata": {},
   "source": [
    "### 🔍 查看PDF转文本结果\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "383ac1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📖 查看文件: 101021acsoprd7b00291.txt\n",
      "==================================================\n",
      "📊 总字符数: 32660\n",
      "📊 总行数: 731\n",
      "\n",
      "📄 前500个字符预览:\n",
      "------------------------------\n",
      "Process Development and Scale-up of the Continuous Flow Nitration\n",
      "of Triﬂuoromethoxybenzene\n",
      "Zhenghui Wen,†,‡ Fengjun Jiao,† Mei Yang,† Shuainan Zhao,†,‡ Feng Zhou,†,‡ and Guangwen Chen*,†\n",
      "†Dalian National Laboratory for Clean Energy, Dalian Institute of Chemical Physics, Chinese Academy of Sciences, Dalian 116023,\n",
      "China\n",
      "‡University of Chinese Academy of Sciences, Beijing 100049, China\n",
      "*\n",
      "S Supporting Information\n",
      "ABSTRACT: In this work, continuous ﬂow nitration of triﬂuoromethoxybenzene (TFMB) was...\n"
     ]
    }
   ],
   "source": [
    "# 选择第一个文件进行详细查看\n",
    "sample_file = output_files[0]\n",
    "print(f\"📖 查看文件: {os.path.basename(sample_file)}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "with open(sample_file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "    content = f.read()\n",
    "    \n",
    "print(f\"📊 总字符数: {len(content)}\")\n",
    "print(f\"📊 总行数: {len(content.splitlines())}\")\n",
    "print(\"\\n📄 前500个字符预览:\")\n",
    "print(\"-\" * 30)\n",
    "print(content[:500] + \"...\" if len(content) > 500 else content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c90caea",
   "metadata": {},
   "source": [
    "### 🔍 结构化PDF解析（可选）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a2aae9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 结构化PDF解析（针对摘要和结论）\n",
      "==================================================\n",
      "\n",
      "📄 处理文件 1/1: 101021acsoprd7b00291.pdf\n",
      "✅ other 章节: 8 个段落 -> /Users/zhaowenyuan/Projects/FCPDExtractor/Data/output/101021acsoprd7b00291/101021acsoprd7b00291_other.txt\n",
      "  ✅ other: 663 个段落\n",
      "\n",
      "🎉 结构化解析完成！\n"
     ]
    }
   ],
   "source": [
    "# 可选：使用结构化解析提取摘要和结论部分\n",
    "print(\"🔍 结构化PDF解析（针对摘要和结论）\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "structured_results = []\n",
    "\n",
    "for i, pdf_path in enumerate(pdf_files, 1):\n",
    "    print(f\"\\n📄 处理文件 {i}/{len(pdf_files)}: {os.path.basename(pdf_path)}\")\n",
    "    \n",
    "    # 使用统一处理器进行结构化解析\n",
    "    result = processor.process_pdf_comprehensive(pdf_path, main_output_dir, mode='structured')\n",
    "    structured_results.append(result)\n",
    "    \n",
    "    # 显示结果\n",
    "    for section, file_path in result.items():\n",
    "        if os.path.exists(file_path):\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                lines = f.readlines()\n",
    "            print(f\"  ✅ {section}: {len(lines)} 个段落\")\n",
    "\n",
    "print(f\"\\n🎉 结构化解析完成！\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8c6cf3",
   "metadata": {},
   "source": [
    "## 📝 步骤 2: 文本预处理\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab72e5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 步骤 2/5: 文本预处理...\n",
      "==================================================\n",
      "\n",
      "📄 处理文件 1/1: 101021acsoprd7b00291.txt\n",
      "  ✅ 预处理完成，过滤了 34 个段落\n",
      "  📁 输出文件: /Users/zhaowenyuan/Projects/FCPDExtractor/Data/output/101021acsoprd7b00291/Processed_101021acsoprd7b00291.txt\n",
      "\n",
      "🎉 文本预处理完成！总共过滤了 34 个段落\n"
     ]
    }
   ],
   "source": [
    "print(\"🚀 步骤 2/5: 文本预处理...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "total_filtered_count = 0\n",
    "processed_files = []\n",
    "\n",
    "# 处理上一步生成的TXT文件，而不是PDF文件\n",
    "for i, txt_file in enumerate(output_files, 1):\n",
    "    print(f\"\\n📄 处理文件 {i}/{len(output_files)}: {os.path.basename(txt_file)}\")\n",
    "    \n",
    "    # 执行文本预处理 - 处理TXT文件\n",
    "    processed_file_path, filtered_count = process_text_file_for_processing(txt_file)\n",
    "    processed_files.append(processed_file_path)\n",
    "    total_filtered_count += filtered_count\n",
    "    \n",
    "    print(f\"  ✅ 预处理完成，过滤了 {filtered_count} 个段落\")\n",
    "    print(f\"  📁 输出文件: {processed_file_path}\")\n",
    "\n",
    "print(f\"\\n🎉 文本预处理完成！总共过滤了 {total_filtered_count} 个段落\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dab9779",
   "metadata": {},
   "source": [
    "### 🔍 查看预处理结果\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8664887d",
   "metadata": {},
   "source": [
    "### 💡 LLM内容过滤说明\n",
    "\n",
    "**这一步的作用：**\n",
    "- 输入：嵌入相似度筛选出的段落（如20个段落）\n",
    "- 处理：使用Nous-Hermes-Llama2-13B模型判断每个段落是否真正与表面化学反应相关\n",
    "- 输出：进一步筛选的相关段落（如10个段落）\n",
    "\n",
    "**模型选择：**\n",
    "- 优先使用：Nous-Hermes-Llama2-13B-Instruct（更智能，性能更好）\n",
    "- 回退模型：nous-hermes-llama2-13b（稳定可靠）\n",
    "\n",
    "**为什么段落数会减少：**\n",
    "- 嵌入相似度只是基于关键词匹配\n",
    "- LLM过滤会进行更智能的内容理解\n",
    "- 最终保留真正相关的段落\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40a707c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 分析文件: 101021acsoprd7b00291.txt\n",
      "==================================================\n",
      "📊 原始文件总行数: 731\n",
      "📊 空行数量: 43\n",
      "📊 分割后的段落数: 43\n",
      "📊 平均段落长度: 756.1 字符\n",
      "\n",
      "📄 前5个段落预览:\n",
      "------------------------------\n",
      "段落 1 (长度: 1160): Process Development and Scale-up of the Continuous Flow Nitration of Triﬂuoromethoxybenzene Zhenghui Wen,†,‡ Fengjun Jiao,† Mei Yang,† Shuainan Zhao,†...\n",
      "段落 2 (长度: 932): Triﬂuoromethoxy aniline is an important intermediate involved in the synthesis of a wide range of ﬁne chemicals, for example, pesticides,1 pharmaceuti...\n",
      "段落 3 (长度: 969): Therefore, it is very important and urgent to develop a new strategy based on process intensiﬁcation technology to improve the productivity and proces...\n",
      "段落 4 (长度: 926): Brocklehurst et al.8 used a commercially available continuous ﬂow reactor to perform the challenging nitration of 2-amino-4-bromobenzoic acid methyl e...\n",
      "段落 5 (长度: 1006): Therefore, the selectivity of m- NB and DNB should be controlled as low as possible to cut the cost of the separation. The objective was to minimize t...\n",
      "\n",
      "📊 总结:\n",
      "  - 原始文件行数: 43\n",
      "  - 预处理后段落数: 25\n",
      "  - 过滤掉的段落数: 18\n",
      "  - 保留比例: 58.1%\n"
     ]
    }
   ],
   "source": [
    "# 详细分析段落分割过程\n",
    "def analyze_paragraph_segmentation(txt_file):\n",
    "    print(f\"🔍 分析文件: {os.path.basename(txt_file)}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    with open(txt_file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    print(f\"📊 原始文件总行数: {len(lines)}\")\n",
    "    \n",
    "    # 模拟段落分割过程\n",
    "    current_segment = []\n",
    "    segments = []\n",
    "    empty_lines_count = 0\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        if line.strip():  # 非空行\n",
    "            current_segment.append(line.strip())\n",
    "        else:  # 空行\n",
    "            empty_lines_count += 1\n",
    "            if current_segment:  # 如果当前段落不为空\n",
    "                segments.append(' '.join(current_segment))\n",
    "                current_segment = []\n",
    "    \n",
    "    # 处理最后一个段落\n",
    "    if current_segment:\n",
    "        segments.append(' '.join(current_segment))\n",
    "    \n",
    "    print(f\"📊 空行数量: {empty_lines_count}\")\n",
    "    print(f\"📊 分割后的段落数: {len(segments)}\")\n",
    "    print(f\"📊 平均段落长度: {sum(len(seg) for seg in segments) / len(segments):.1f} 字符\")\n",
    "    \n",
    "    print(\"\\n📄 前5个段落预览:\")\n",
    "    print(\"-\" * 30)\n",
    "    for i, segment in enumerate(segments[:5]):\n",
    "        print(f\"段落 {i+1} (长度: {len(segment)}): {segment[:150]}...\" if len(segment) > 150 else f\"段落 {i+1} (长度: {len(segment)}): {segment}\")\n",
    "    \n",
    "    return segments\n",
    "\n",
    "# 分析原始TXT文件的段落分割\n",
    "if output_files:\n",
    "    original_segments = analyze_paragraph_segmentation(output_files[0])\n",
    "    \n",
    "    print(f\"\\n📊 总结:\")\n",
    "    print(f\"  - 原始文件行数: {len(original_segments)}\")\n",
    "    print(f\"  - 预处理后段落数: 25\")\n",
    "    print(f\"  - 过滤掉的段落数: {len(original_segments) - 25}\")\n",
    "    print(f\"  - 保留比例: {25/len(original_segments)*100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6b4595",
   "metadata": {},
   "source": [
    "## 🔍 步骤 3: 嵌入和相似度计算\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1d9b5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 步骤 3/5: 嵌入和相似度计算...\n",
      "==================================================\n",
      "\n",
      "📄 处理文件 1/1: Processed_101021acsoprd7b00291.txt\n",
      "  ✅ 嵌入和相似度计算完成\n",
      "  📁 输出文件: /Users/zhaowenyuan/Projects/FCPDExtractor/Data/output/101021acsoprd7b00291/Embedding_101021acsoprd7b00291.txt\n",
      "\n",
      "🎉 嵌入和相似度计算完成！\n"
     ]
    }
   ],
   "source": [
    "print(\"🚀 步骤 3/5: 嵌入和相似度计算...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "embedding_files = []\n",
    "\n",
    "# 使用上一步预处理后的文件\n",
    "for i, processed_file in enumerate(processed_files, 1):\n",
    "    print(f\"\\n📄 处理文件 {i}/{len(processed_files)}: {os.path.basename(processed_file)}\")\n",
    "    \n",
    "    # 执行嵌入和相似度计算\n",
    "    embedding_file_path = process_text_file_for_embedding(processed_file)\n",
    "    embedding_files.append(embedding_file_path)\n",
    "    \n",
    "    print(f\"  ✅ 嵌入和相似度计算完成\")\n",
    "    print(f\"  📁 输出文件: {embedding_file_path}\")\n",
    "\n",
    "print(f\"\\n🎉 嵌入和相似度计算完成！\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f572a33b",
   "metadata": {},
   "source": [
    "### 🔍 查看嵌入结果\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0bc8271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📖 查看嵌入文件: Embedding_101021acsoprd7b00291.txt\n",
      "==================================================\n",
      "📊 嵌入相似度筛选后段落数: 20\n",
      "\n",
      "📄 相似度最高的段落预览:\n",
      "------------------------------\n",
      "段落 1: The general laboratory process developments were carried out in microchannel reactors. TFMB (7.57 M, ﬂow rate of 0.4−1.0 mL·min−1) and a solution of fuming nitric acid in concentrated sulfuric acid (2...\n",
      "段落 3: A faster ﬂow rate would result in a better mixing eﬀect, which can make the organic compound more evenly dispersed in the acid phase. Besides, a faster ﬂow rate would also decrease the residence time....\n"
     ]
    }
   ],
   "source": [
    "# 查看嵌入结果\n",
    "sample_embedding = embedding_files[0]\n",
    "print(f\"📖 查看嵌入文件: {os.path.basename(sample_embedding)}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "with open(sample_embedding, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "print(f\"📊 嵌入相似度筛选后段落数: {len(lines)}\")\n",
    "print(\"\\n📄 相似度最高的段落预览:\")\n",
    "print(\"-\" * 30)\n",
    "for i, line in enumerate(lines[:3]):\n",
    "    if line.strip():\n",
    "        print(f\"段落 {i+1}: {line[:200]}...\" if len(line) > 200 else f\"段落 {i+1}: {line}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4860a8f4",
   "metadata": {},
   "source": [
    "## 🤖 步骤 4: LLM内容过滤\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9af29236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 步骤 4/5: LLM内容过滤...\n",
      "==================================================\n",
      "\n",
      "📄 处理文件 1/1: Embedding_101021acsoprd7b00291.txt\n",
      "🔍 尝试加载模型，路径: /Users/zhaowenyuan/Projects/FCPDExtractor/models\n",
      "✅ 成功加载 nous-hermes-llama2-13b.Q4_0.gguf 模型\n",
      "🔍 处理文件: Embedding_101021acsoprd7b00291.txt\n",
      "==================================================\n",
      "📊 原始段落数: 10\n",
      "\n",
      "🤖 步骤1: LLM内容过滤...\n",
      "...开始使用LLM进行段落分类...\n",
      "...分类完成，保留 10 个相关段落。\n",
      "✅ 过滤后段落数: 10\n",
      "  ✅ LLM内容过滤完成\n",
      "  📁 输出文件: /Users/zhaowenyuan/Projects/FCPDExtractor/Data/output/101021acsoprd7b00291/Embedding_101021acsoprd7b00291_Filtered.txt\n",
      "\n",
      "🎉 LLM内容过滤完成！\n"
     ]
    }
   ],
   "source": [
    "print(\"🚀 步骤 4/5: LLM内容过滤...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "filter_files = []\n",
    "\n",
    "for i, embedding_file in enumerate(embedding_files, 1):\n",
    "    print(f\"\\n📄 处理文件 {i}/{len(embedding_files)}: {os.path.basename(embedding_file)}\")\n",
    "    \n",
    "    # 执行LLM内容过滤\n",
    "    filter_file_path = process_text_file_for_filter(embedding_file)\n",
    "    filter_files.append(filter_file_path)\n",
    "    \n",
    "    print(f\"  ✅ LLM内容过滤完成\")\n",
    "    print(f\"  📁 输出文件: {filter_file_path}\")\n",
    "    \n",
    "kept = sum(1 for _ in open(filter_files[-1], 'r', encoding='utf-8', errors='ignore') if _.strip())\n",
    "if kept == 0:\n",
    "    print(\"⚠️ 过滤为空，回退用嵌入Top-N\")\n",
    "    filter_files[-1] = embedding_files[-1]\n",
    "\n",
    "print(f\"\\n🎉 LLM内容过滤完成！\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4522a3d6",
   "metadata": {},
   "source": [
    "### 🔍 查看LLM过滤结果\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4def142c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📖 查看过滤文件: Embedding_101021acsoprd7b00291_Filtered.txt\n",
      "==================================================\n",
      "📊 LLM过滤后段落数: 20\n",
      "\n",
      "📄 过滤后的段落预览:\n",
      "------------------------------\n",
      "段落 1: The general laboratory process developments were carried out in microchannel reactors. TFMB (7.57 M, ﬂow rate of 0.4−1.0 mL·min−1) and a solution of fuming nitric acid in concentrated sulfuric acid (2...\n",
      "段落 3: A faster ﬂow rate would result in a better mixing eﬀect, which can make the organic compound more evenly dispersed in the acid phase. Besides, a faster ﬂow rate would also decrease the residence time....\n"
     ]
    }
   ],
   "source": [
    "# 查看LLM过滤结果\n",
    "sample_filter = filter_files[0]\n",
    "print(f\"📖 查看过滤文件: {os.path.basename(sample_filter)}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "with open(sample_filter, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "print(f\"📊 LLM过滤后段落数: {len(lines)}\")\n",
    "print(\"\\n📄 过滤后的段落预览:\")\n",
    "print(\"-\" * 30)\n",
    "for i, line in enumerate(lines[:3]):\n",
    "    if line.strip():\n",
    "        print(f\"段落 {i+1}: {line[:200]}...\" if len(line) > 200 else f\"段落 {i+1}: {line}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcd10843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STRICT = meta-llama-3.1-8b-instruct-q4_k_m-2.gguf\n"
     ]
    }
   ],
   "source": [
    "# 1) 设置严格模型名到你新下的本地文件\n",
    "import os, importlib\n",
    "os.environ[\"FCPD_STRICT_MODEL_NAME\"] = \"meta-llama-3.1-8b-instruct-q4_k_m-2.gguf\"\n",
    "print(\"STRICT =\", os.getenv(\"FCPD_STRICT_MODEL_NAME\"))\n",
    "\n",
    "# 2) 强制重载模块，并重新导入函数，避免用到旧版本\n",
    "import Unified_Text_Processor as UTP\n",
    "importlib.reload(UTP)\n",
    "from Unified_Text_Processor import process_text_file_for_summerized\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88626257",
   "metadata": {},
   "source": [
    "## 📊 步骤 5: 抽象和总结\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a11b502a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 步骤 5/5: 抽象和总结...\n",
      "==================================================\n",
      "\n",
      "📄 处理文件 1/1: Embedding_101021acsoprd7b00291_Filtered.txt\n",
      "  ⏳  正在执行 [抽象]...\n",
      "🔍 尝试加载模型，路径: /Users/zhaowenyuan/Projects/FCPDExtractor/models\n",
      "✅ 成功加载 nous-hermes-llama2-13b.Q4_0.gguf 模型\n",
      "🔍 处理文件: Embedding_101021acsoprd7b00291_Filtered.txt\n",
      "==================================================\n",
      "📊 原始段落数: 10\n",
      "\n",
      "📝 步骤2: 文本抽象...\n",
      "Abstract 1/10:\n",
      "The general laboratory process developments were carried out in microchannel reactors. TFMB (7.57 M, ﬂow rate of 0.4−1.0 mL·min−1) and a solution of fuming nitric acid in concentrated sulfuric acid (2.49−3.19 M, ﬂow rate of 0.8− 2.2 mL·min−1) were delivered by two syringe pumps (TYD01- 02, Lead Fluid), respectively. The ﬂuids reacted in capillaries with a length deﬁned by the desired residence tim\n",
      "Abstract 2/10:\n",
      "A faster ﬂow rate would result in a better mixing eﬀect, which can make the organic compound more evenly dispersed in the acid phase. Besides, a faster ﬂow rate would also decrease the residence time. Therefore, a faster ﬂow rate could reduce the occurrence of dinitration. 2.1.6. Eﬀect of Reactor Structure. Considering that the nitration processes were limited by the mass transfer in microchannel \n",
      "Abstract 3/10:\n",
      "TFMB (7.57 M, ﬂow rate of 10−20 mL·min−1) and a solution of fuming nitric acid in concentrated sulfuric acid (3.19 M, ﬂow rate of 24−39 mL·min−1) were pumped into microreactor by two metering pumps (P1, P2, SSI, USA), respectively. The temperature of the microreactor was controlled by the microchannel heat exchanger which is integrated in the microreactor system. Then the mixed solution was introd\n",
      "Abstract 4/10:\n",
      "The highest conversion (99.6%) of reactant was obtained in the microchannel coupled with tubular reactor system at the condition of N/S = 0.25, N/F = 1.1, φ = 97 wt %, T = 273 K, Qor = 0.4 mL·min−1, and Qaq = 0.9 mL· min−1, with the selectivity of o-NB, m-NB, p-NB, and DNB being 7.26%, 0.08%, 90.97%, and 1.04%, respectively. Encouraged by the lab-scale results, the scale-up of the nitration of TFM\n",
      "Abstract 5/10:\n",
      "Process Development and Scale-up of the Continuous Flow Nitration of Triﬂuoromethoxybenzene Zhenghui Wen,†,‡ Fengjun Jiao,† Mei Yang,† Shuainan Zhao,†,‡ Feng Zhou,†,‡ and Guangwen Chen*,† †Dalian National Laboratory for Clean Energy, Dalian Institute of Chemical Physics, Chinese Academy of Sciences, Dalian 116023, China ‡University of Chinese Academy of Sciences, Beijing 100049, China * S Supporti\n",
      "Abstract 6/10:\n",
      "The quartz sand microparticles with an average size of 710 μm were packed in the tubular reactor at a porosity of 0.39. It is observed from Figure 7a that TFMB is totally converted at the low ﬂow rate and then the conversion decreases directly with the increasing ﬂow rate. Given such a low volume of the microreactor system, multiply increasing ﬂow rates lead to a shorter residence time which is no\n",
      "Abstract 7/10:\n",
      "with the conversion of TFMB being 99.6%. The results showed that the microreactor coupled with distributed packed tubular reactor could conduct the continuous ﬂow nitration of TFMB well with a good performance. The precise control of temperature distribution and the eﬃcient mixing in micro- reactor ensured the nitration reaction proceeded at a fast rate and minimized the formation of the byproduct\n",
      "Abstract 8/10:\n",
      "Therefore, the selectivity of m- NB and DNB should be controlled as low as possible to cut the cost of the separation. The objective was to minimize the byproduct selectivity (m-NB < 0.1%, DNB < 1.5%) without decline of the product yield, which could bring signiﬁcant economic beneﬁts in saving costs of downstream separation and products puriﬁcation. First, the eﬀects of process parameters on the c\n",
      "Abstract 9/10:\n",
      "The mixture then ﬂowed through the microreactor which was cooled by running water. After the quick mixing in microreactor Figure 7. Eﬀect of ﬂow rate on the (a) conversion of TFMB and (b, c) product selectivity in a packed microchannel system. N/S = 0.25, N/F = 1.1, φ = 97 wt %, T = 273 K. Organic Process Research & Development Article DOI: 10.1021/acs.oprd.7b00291 Org. Process Res. Dev. 2017, 21,\n",
      "Abstract 10/10:\n",
      "91.08% of p-NB, 7.05% of o-NB, and only trace of m-NB (0.08%) and DNB (1.34%) were obtained, Figure 8. Schematic setup of strategy A for the scale up of the continuous ﬂow TFMB nitration. (a) 3D model of setup of strategy A (b) cutaway picture of packed tubular reactor (red blocks represent packed microparticles). Table 1. Screen of the Size of the Packed Particle on the Scale up of the Continuous\n",
      "  ✅ 抽象完成: Embedding_101021acsoprd7b00291_Filtered_Abstract.txt\n",
      "  ⏳  正在执行 [总结]...\n",
      "🔍 尝试加载模型，路径: /Users/zhaowenyuan/Projects/FCPDExtractor/models\n",
      "🔒 严格模式，目标模型: meta-llama-3.1-8b-instruct-q4_k_m-2.gguf\n",
      "✅ 成功加载(严格, 本地models目录) meta-llama-3.1-8b-instruct-q4_k_m-2.gguf 模型\n",
      "🔍 处理文件: Embedding_101021acsoprd7b00291_Filtered_Abstract.txt\n",
      "==================================================\n",
      "📊 原始段落数: 10\n",
      "\n",
      "📊 步骤3: 参数总结...\n",
      "🔥 Warmup output: [ \n",
      "\n",
      "(Note: This paragraph does not contain] (len=41)\n",
      "🔥 Summarize warmup passed.\n",
      "Summarized 1/10:\n",
      "### Step-by-Step Solution ###\n",
      "\n",
      "## Step 1: Identify the reaction type\n",
      "The paragraph does not explicitly mention a specific chemical reaction or process beyond mentioning it as part of general laboratory process developments. Therefore, we will leave this field blank.\n",
      "\n",
      "## Step 2: Extract reactants and their roles\n",
      "From the text, two substances are mentioned:\n",
      "- TFMB (7.57 M) delivered by one syringe pump.\n",
      "- A solution of fuming nitric acid in concentrated sulfuric acid (2.49−3.19 M), also delivered by a separate syringe pump.\n",
      "\n",
      "Given that both are involved in reacting within capillaries, we can infer they act as reactants but cannot determine their roles without further context or information on the reaction type.\n",
      "\n",
      "## Step 3: Extract products and yields\n",
      "There is no mention of specific chemical products formed from this process. Therefore, we will leave these fields blank for now.\n",
      "\n",
      "## Step 4: Determine conditions\n",
      "- Temperature: Not explicitly mentioned.\n",
      "- Residence Time: The length of capillaries was defined by the desired residence time but not specified in units or value.\n",
      "- Flow Rate:\n",
      "    - For TFMB (reactant A): Given as a range, \"0.4−1.0 mL·min−1\".\n",
      "    - Total flow rate is mentioned for fuming nitric acid solution (\"0.8−2.2 mL·min−1\"), but we need to infer the total based on\n",
      "Summarized 2/10:\n",
      "### Step-by-Step Solution ###\n",
      "\n",
      "## Step 1: Identify the reaction type\n",
      "The paragraph does not explicitly mention a specific chemical reaction or process it is referring to. Therefore, we will leave this field as null.\n",
      "\n",
      "## Step 2: Extract reactants and their roles\n",
      "There are no explicit mentions of reactant names in the provided text. Thus, we cannot accurately fill out the \"reactants\" section with any meaningful information beyond what's already stated (none).\n",
      "\n",
      "## Step 3: Identify products and optimal yield\n",
      "The paragraph does not explicitly mention a product or its yield directly related to the process being discussed. However, it mentions an organic compound becoming more evenly dispersed in the acid phase due to better mixing effects at faster flow rates.\n",
      "\n",
      "## Step 4: Extract conditions for the reaction\n",
      "- Temperature is mentioned as relevant but no specific value is given.\n",
      "- Residence time is also mentioned and implied to be affected by a faster flow rate.\n",
      "- Flow rate of reactant A (or total) isn't explicitly stated, so we'll leave this field empty since it's not directly provided in the text.\n",
      "\n",
      "## Step 5: Determine reactor type and inner diameter\n",
      "The paragraph mentions \"microchannel\" as part of the nitration process but does not specify a particular reactor type or its dimensions. However, given that microchannels are often associated with specific types of reactors (like microreactors), we might infer some details about the setup.\n",
      "\n",
      "## Step 6: Calculate metrics\n",
      "Summarized 3/10:\n",
      "### Step-by-Step Solution ###\n",
      "To solve this task, we will follow these steps:\n",
      "\n",
      "1. Identify the reaction type.\n",
      "2. Extract reactants and their roles (reactant/catalyst/solvent).\n",
      "3. Determine products with optimal yield percentage.\n",
      "4. Gather conditions: temperature in °C, residence time in min, flow rate of each reagent in mL/min, total flow rate in mL/min, pressure is not mentioned so we will use null for it.\n",
      "5. Identify the reactor type and inner diameter.\n",
      "\n",
      "### Step 1: Reaction Type\n",
      "The reaction type is not explicitly stated; therefore, we set \"reaction_type\" to null.\n",
      "\n",
      "```json\n",
      "\"reaction_summary\": {\n",
      "    \"reaction_type\": null,\n",
      "```\n",
      "\n",
      "### Step 2: Reactants\n",
      "We have two reactant solutions but no indication of their chemical names. We will assume they are the focus of the reaction and thus mark them as reactants without specifying roles since we cannot infer from given text.\n",
      "\n",
      "```json\n",
      "\"reactants\":[{\n",
      "    \"name\": null,\n",
      "```\n",
      "\n",
      "### Step 3: Products\n",
      "There is mention of a mixed solution being introduced into the microreactor, but no specific products are mentioned. We will assume there might be some form of product or outcome and set yield to optimal at 95% as it's the closest information we have regarding outcomes.\n",
      "\n",
      "```json\n",
      "\"products\":[{\n",
      "    \"name\": null,\n",
      "    \"yield_optimal\": 95,\n",
      "```\n",
      "Summarized 4/10:\n",
      "{\"name\":\"TFM\",\"role\":\"reactant\"}\n",
      "Summarized 5/10:\n",
      "### Input Text ###\n",
      "Process Development and Scale-up of the Continuous Flow Nitration of Triﬂuoromethoxybenzene Zhenghui Wen,†,‡ Fengjun Jiao,† Mei Yang,† Shuainan Zhao,†,‡ Feng Zhou,†,‡ and Guangwen Chen*,† †Dalian National Laboratory for Clean Energy, Dalian Institute of Chemical Physics, Chinese Academy of Sciences, Dalian 116023, China ‡University of Chinese Academy of Sciences, Beijing 100049, China * S Supporti\n",
      "\n",
      "### Step 1: Identify the reaction type\n",
      "The text does not explicitly mention the reaction type.\n",
      "\n",
      "### Step 2: Extract reactants and their roles\n",
      "There are no explicit mentions of reactants in the provided paragraph. Therefore, we will leave this field as null for now.\n",
      "\n",
      "### Step 3: Determine products and optimal yield\n",
      "The product is Triﬂuoromethoxybenzene but it's being nitrated so let's call it \"Triﬂuoromethoxybenzonitrate\". The text does not explicitly mention the optimal yield, but we can infer that since there are no other products mentioned and this seems to be a process development paper for nitration of Triﬂuoromethoxybenzene, then 95% is likely correct.\n",
      "\n",
      "### Step 4: Extract conditions\n",
      "The paragraph mentions \"Continuous Flow Nitration\" which implies the use of\n",
      "Summarized 6/10:\n",
      "{\"name\": \"null\", \"role\": \"null\"}\n",
      "Summarized 7/10:\n",
      "{\n",
      "    \"name\":\"TFMB\",\n",
      "    \"role\":null\n",
      "}],\n",
      "\"products\":[{\n",
      "    \"name\": null,\n",
      "    \"yield_optimal\": 99.6, # Assuming yield optimal is the same as conversion rate given in paragraph.\n",
      "    \"unit\": \"%\"\n",
      "}\n",
      "Summarized 8/10:\n",
      "{\"name\": \"m-NB\", \"role\": \"reactant\"},\n",
      "    {\"name\": \"DNB\", \"role\": \"reactant\"}\n",
      "]\n",
      "products = [{\"name\": null, \"yield_optimal\": 95, \"unit\": \"%\"}\n",
      "Summarized 9/10:\n",
      "### Step-by-Step Solution ###\n",
      "\n",
      "## Step 1: Identify the reaction type\n",
      "The paragraph does not explicitly mention the reaction type.\n",
      "\n",
      "## Step 2: Extract reactants and their roles\n",
      "There is no information about specific reactants in this text. However, TFMB (presumably a chemical compound) is mentioned as part of an effect study on flow rate but its role isn't specified beyond being affected by conditions.\n",
      "\n",
      "## Step 3: Identify products with optimal yield\n",
      "The paragraph mentions the product selectivity for TFMB conversion but does not explicitly state any other products. However, it implies that there are multiple products since \"product\" is mentioned in plural form (\"products\").\n",
      "\n",
      "## Step 4: Extract reaction conditions\n",
      "- Temperature (T) = 273 K.\n",
      "- Flow rate information isn't directly provided; however, the effect of flow rate on conversion and selectivity suggests its importance but doesn’t give a specific value.\n",
      "\n",
      "## Step 5: Determine reactor type and inner diameter\n",
      "The microreactor is cooled by running water. The text does not explicitly mention the inner diameter or provide enough detail to infer it accurately without additional context that isn't provided.\n",
      "\n",
      "## Step 6: Extract metrics (conversion, yield, selectivity)\n",
      "- Conversion of TFMB = Not directly stated but implied in Figure 7.\n",
      "- Selectivity is mentioned as affected by flow rate but no specific value is given for any product.\n",
      "- Yield information isn’t explicitly available; however, the mention\n",
      "Summarized 10/10:\n",
      "{\"name\": null,\"role\":\"null\"}],\n",
      "\"products\":[{\"name\": \"p-Nitrobenzene\",\"yield_optimal\": 91.08, \"unit\": \"%\"}, {\"name\": \"o-Nitrobenzene\", \"yield_optimal\": 7.05, \"unit\": \"%\"}\n",
      "  ✅ 总结完成: Embedding_101021acsoprd7b00291_Filtered_Abstract_Summarized.txt\n",
      "\n",
      "🎉 抽象和总结完成！\n"
     ]
    }
   ],
   "source": [
    "import os # 确保 os 模块已导入\n",
    "\n",
    "print(\"🚀 步骤 5/5: 抽象和总结...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "abstract_files = []\n",
    "summarized_files = []\n",
    "\n",
    "# 使用过滤后的文件进行抽象和总结\n",
    "for i, filter_file in enumerate(filter_files, 1):\n",
    "    print(f\"\\n📄 处理文件 {i}/{len(filter_files)}: {os.path.basename(filter_file)}\")\n",
    "    \n",
    "\n",
    "    # --- 抽象 (Abstract) 步骤 ---\n",
    "    # 1. 首先，根据输入文件名，推断出输出文件的应有路径\n",
    "    #    例如，将 '..._Filtered.txt' 替换为 '..._Abstract.txt'\n",
    "    abstract_file_path = filter_file.replace('_Filtered.txt', '_Abstract.txt')\n",
    "\n",
    "    # 2. 检查这个输出文件是否已经存在\n",
    "    if os.path.exists(abstract_file_path):\n",
    "        # 如果文件已存在，则跳过处理\n",
    "        print(f\"  ⏭️  检测到已存在文件，跳过 [抽象] 步骤: {os.path.basename(abstract_file_path)}\")\n",
    "    else:\n",
    "        # 如果文件不存在，才执行耗时的LLM调用\n",
    "        print(\"  ⏳  正在执行 [抽象]...\")\n",
    "        # 注意：这里我们假设 process_text_file_for_abstract 返回的是它创建的文件路径\n",
    "        abstract_file_path = process_text_file_for_abstract(filter_file)\n",
    "        print(f\"  ✅ 抽象完成: {os.path.basename(abstract_file_path)}\")\n",
    "    \n",
    "    # 无论是否跳过，都将路径添加到列表中\n",
    "    abstract_files.append(abstract_file_path)\n",
    "\n",
    "    # --- 总结 (Summarize) 步骤 ---\n",
    "    # 1. 同样，先推断出输出文件的路径\n",
    "    summarized_file_path = filter_file.replace('_Filtered.txt', '_Summarized.txt')\n",
    "\n",
    "    # 2. 检查文件是否存在\n",
    "    if os.path.exists(summarized_file_path):\n",
    "        # 如果已存在，则跳过\n",
    "        print(f\"  ⏭️  检测到已存在文件，跳过 [总结] 步骤: {os.path.basename(summarized_file_path)}\")\n",
    "    else:\n",
    "        # 如果不存在，才执行\n",
    "        # 重要提示：根据我们之前的讨论，总结步骤的最佳输入是“抽象”后的文本，而不是“过滤”后的文本。\n",
    "        # 因此，这里传递 abstract_file_path 作为输入会更高效和准确。\n",
    "        print(\"  ⏳  正在执行 [总结]...\")\n",
    "        summarized_file_path = process_text_file_for_summerized(abstract_file_path)\n",
    "        print(f\"  ✅ 总结完成: {os.path.basename(summarized_file_path)}\")\n",
    "\n",
    "    # 无论是否跳过，都将路径添加到列表中\n",
    "    summarized_files.append(summarized_file_path)\n",
    "\n",
    "\n",
    "print(f\"\\n🎉 抽象和总结完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44237bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📖 查看嵌入文件: Embedding_101021acsoprd7b00291.txt\n",
      "==================================================\n",
      "📊 嵌入相似度筛选后段落数: 20\n",
      "\n",
      "📄 相似度最高的段落预览:\n",
      "------------------------------\n",
      "段落 1: The general laboratory process developments were carried out in microchannel reactors. TFMB (7.57 M, ﬂow rate of 0.4−1.0 mL·min−1) and a solution of fuming nitric acid in concentrated sulfuric acid (2...\n",
      "段落 3: A faster ﬂow rate would result in a better mixing eﬀect, which can make the organic compound more evenly dispersed in the acid phase. Besides, a faster ﬂow rate would also decrease the residence time....\n"
     ]
    }
   ],
   "source": [
    "# 查看嵌入结果\n",
    "sample_embedding = embedding_files[0]\n",
    "print(f\"📖 查看嵌入文件: {os.path.basename(sample_embedding)}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "with open(sample_embedding, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "print(f\"📊 嵌入相似度筛选后段落数: {len(lines)}\")\n",
    "print(\"\\n📄 相似度最高的段落预览:\")\n",
    "print(\"-\" * 30)\n",
    "for i, line in enumerate(lines[:3]):\n",
    "    if line.strip():\n",
    "        print(f\"段落 {i+1}: {line[:200]}...\" if len(line) > 200 else f\"段落 {i+1}: {line}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dceb377e",
   "metadata": {},
   "source": [
    "### 🔍 查看最终结果\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38340a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📖 查看最终总结: Embedding_101021acsoprd7b00291_Filtered_Abstract_Summarized.txt\n",
      "==================================================\n",
      "📊 总结内容长度: 7311 字符\n",
      "\n",
      "📄 总结内容预览:\n",
      "------------------------------\n",
      "### Step-by-Step Solution ###\n",
      "\n",
      "## Step 1: Identify the reaction type\n",
      "The paragraph does not explicitly mention a specific chemical reaction or process beyond mentioning it as part of general laboratory process developments. Therefore, we will leave this field blank.\n",
      "\n",
      "## Step 2: Extract reactants and their roles\n",
      "From the text, two substances are mentioned:\n",
      "- TFMB (7.57 M) delivered by one syringe pump.\n",
      "- A solution of fuming nitric acid in concentrated sulfuric acid (2.49−3.19 M), also delivered by a separate syringe pump.\n",
      "\n",
      "Given that both are involved in reacting within capillaries, we can infer they act as reactants but cannot determine their roles without further context or information on the reaction type.\n",
      "\n",
      "## Step 3: Extract products and yields\n",
      "There is no mention of specific chemical products formed from this process. Therefore, we will leave these fields blank for now.\n",
      "\n",
      "## Step 4: Determine conditions\n",
      "- Temperature: Not explicitly mentioned.\n",
      "- Residence Time: The length of capill...\n"
     ]
    }
   ],
   "source": [
    "# 查看最终总结结果\n",
    "sample_summarized = summarized_files[0]\n",
    "print(f\"📖 查看最终总结: {os.path.basename(sample_summarized)}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "with open(sample_summarized, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "    content = f.read()\n",
    "    \n",
    "print(f\"📊 总结内容长度: {len(content)} 字符\")\n",
    "print(\"\\n📄 总结内容预览:\")\n",
    "print(\"-\" * 30)\n",
    "print(content[:1000] + \"...\" if len(content) > 1000 else content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47901c5c",
   "metadata": {},
   "source": [
    "## 📊 处理结果统计\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a0cd50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 OSSExtractor 处理结果统计\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>文件</th>\n",
       "      <th>原始PDF (MB)</th>\n",
       "      <th>预处理 (KB)</th>\n",
       "      <th>嵌入筛选 (KB)</th>\n",
       "      <th>LLM过滤 (KB)</th>\n",
       "      <th>最终总结 (KB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101021acsoprd7b00291.txt</td>\n",
       "      <td>0.03</td>\n",
       "      <td>26.96</td>\n",
       "      <td>8.26</td>\n",
       "      <td>8.26</td>\n",
       "      <td>7.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         文件  原始PDF (MB)  预处理 (KB)  嵌入筛选 (KB)  LLM过滤 (KB)  \\\n",
       "0  101021acsoprd7b00291.txt        0.03     26.96       8.26        8.26   \n",
       "\n",
       "   最终总结 (KB)  \n",
       "0       7.19  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎉 所有处理步骤完成！\n"
     ]
    }
   ],
   "source": [
    "# 统计处理结果\n",
    "print(\"📊 OSSExtractor 处理结果统计\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "stats = []\n",
    "for i, file_path in enumerate(output_files):\n",
    "    filename = os.path.basename(file_path)\n",
    "    \n",
    "    # 统计各个步骤的文件大小\n",
    "    original_size = os.path.getsize(file_path) if os.path.exists(file_path) else 0\n",
    "    \n",
    "    processed_file = processed_files[i] if i < len(processed_files) else None\n",
    "    processed_size = os.path.getsize(processed_file) if processed_file and os.path.exists(processed_file) else 0\n",
    "    \n",
    "    embedding_file = embedding_files[i] if i < len(embedding_files) else None\n",
    "    embedding_size = os.path.getsize(embedding_file) if embedding_file and os.path.exists(embedding_file) else 0\n",
    "    \n",
    "    filter_file = filter_files[i] if i < len(filter_files) else None\n",
    "    filter_size = os.path.getsize(filter_file) if filter_file and os.path.exists(filter_file) else 0\n",
    "    \n",
    "    summarized_file = summarized_files[i] if i < len(summarized_files) else None\n",
    "    summarized_size = os.path.getsize(summarized_file) if summarized_file and os.path.exists(summarized_file) else 0\n",
    "    \n",
    "    stats.append({\n",
    "        '文件': filename,\n",
    "        '原始PDF (MB)': round(original_size / 1024 / 1024, 2),\n",
    "        '预处理 (KB)': round(processed_size / 1024, 2),\n",
    "        '嵌入筛选 (KB)': round(embedding_size / 1024, 2),\n",
    "        'LLM过滤 (KB)': round(filter_size / 1024, 2),\n",
    "        '最终总结 (KB)': round(summarized_size / 1024, 2)\n",
    "    })\n",
    "\n",
    "# 显示统计表格\n",
    "df_stats = pd.DataFrame(stats)\n",
    "display(df_stats)\n",
    "\n",
    "print(\"\\n🎉 所有处理步骤完成！\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147de13a",
   "metadata": {},
   "source": [
    "## 🔧 调试和优化建议\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d08b082",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🔧 调试和优化建议\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\"\"\n",
    "1. 📊 检查嵌入相似度阈值\n",
    "   - 如果筛选的段落太少，可以降低相似度阈值\n",
    "   - 如果筛选的段落太多，可以提高相似度阈值\n",
    "\n",
    "2. 🤖 优化LLM提示词\n",
    "   - 在Filter.py中调整问题描述\n",
    "   - 在Summerized.py中调整参数提取提示词\n",
    "\n",
    "3. 📝 调整文本预处理\n",
    "   - 在TXT_Processing.py中修改过滤规则\n",
    "   - 调整段落分割策略\n",
    "\n",
    "4. 🔍 检查模型性能\n",
    "   - 观察LLM的响应质量\n",
    "   - 考虑调整模型参数（temp, top_p等）\n",
    "\n",
    "5. 📈 可视化处理流程\n",
    "   - 绘制各步骤的数据量变化\n",
    "   - 分析处理效率\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3912b46",
   "metadata": {},
   "source": [
    "## 📊 结果查看和分析\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b00104c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 查看处理结果...\n",
      "==================================================\n",
      "\n",
      "📁 原始文本:\n",
      "  1. 101021acsoprd7b00291.txt (731 行)\n",
      "\n",
      "📁 预处理文本:\n",
      "  1. Processed_101021acsoprd7b00291.txt (68 行)\n",
      "\n",
      "📁 嵌入文件:\n",
      "  1. Embedding_101021acsoprd7b00291.txt (20 行)\n",
      "\n",
      "📁 过滤文件:\n",
      "  1. Embedding_101021acsoprd7b00291_Filtered.txt (20 行)\n",
      "\n",
      "📁 抽象文件:\n",
      "  1. Embedding_101021acsoprd7b00291_Filtered_Abstract.txt (20 行)\n",
      "\n",
      "📁 总结文件:\n",
      "  1. Embedding_101021acsoprd7b00291_Filtered_Abstract_Summarized.txt (137 行)\n",
      "\n",
      "🎉 处理完成！共处理了 1 个PDF文件\n"
     ]
    }
   ],
   "source": [
    "# 查看最终结果\n",
    "print(\"📊 查看处理结果...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 显示所有生成的文件\n",
    "all_files = {\n",
    "    '原始文本': output_files,\n",
    "    '预处理文本': processed_files,\n",
    "    '嵌入文件': embedding_files,\n",
    "    '过滤文件': filter_files,\n",
    "    '抽象文件': abstract_files,\n",
    "    '总结文件': summarized_files\n",
    "}\n",
    "\n",
    "for category, files in all_files.items():\n",
    "    print(f\"\\n📁 {category}:\")\n",
    "    for i, file in enumerate(files, 1):\n",
    "        if os.path.exists(file):\n",
    "            with open(file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                lines = f.readlines()\n",
    "            print(f\"  {i}. {os.path.basename(file)} ({len(lines)} 行)\")\n",
    "        else:\n",
    "            print(f\"  {i}. {os.path.basename(file)} (文件不存在)\")\n",
    "\n",
    "print(f\"\\n🎉 处理完成！共处理了 {len(pdf_files)} 个PDF文件\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b6f7ab",
   "metadata": {},
   "source": [
    "## 🔍 结果分析\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65ff5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 分析最终结果...\n",
      "==================================================\n",
      "📄 最终总结结果:\n",
      "\n",
      "文件 1: Embedding_101021acsoprd7b00291_Filtered_Abstract_Summarized.txt\n",
      "内容预览:\n",
      "------------------------------\n",
      "### Step-by-Step Solution ###\n",
      "\n",
      "## Step 1: Identify the reaction type\n",
      "The paragraph does not explicitly mention a specific chemical reaction or process beyond mentioning it as part of general laboratory process developments. Therefore, we will leave this field blank.\n",
      "\n",
      "## Step 2: Extract reactants and their roles\n",
      "From the text, two substances are mentioned:\n",
      "- TFMB (7.57 M) delivered by one syringe pump.\n",
      "- A solution of fuming nitric acid in concentrated sulfuric acid (2.49−3.19 M), also delivered ...\n"
     ]
    }
   ],
   "source": [
    "# 分析最终结果\n",
    "print(\"🔍 分析最终结果...\")\n",
    "print(\"=\" * 50)\n",
    "# 查看总结文件的内容\n",
    "if summarized_files:\n",
    "    print(\"📄 最终总结结果:\")\n",
    "    for i, file in enumerate(summarized_files, 1):\n",
    "        print(f\"\\n文件 {i}: {os.path.basename(file)}\")\n",
    "        if os.path.exists(file):\n",
    "            with open(file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                content = f.read()\n",
    "            print(\"内容预览:\")\n",
    "            print(\"-\" * 30)\n",
    "            print(content[:500] + \"...\" if len(content) > 500 else content)\n",
    "        else:\n",
    "            print(\"文件不存在\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712c2321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 显示处理统计信息\n",
    "print(\"\\n📊 处理统计信息:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "total_paragraphs_original = 0\n",
    "total_paragraphs_filtered = 0\n",
    "\n",
    "for i, (original, filtered) in enumerate(zip(processed_files, filter_files), 1):\n",
    "    if os.path.exists(original):\n",
    "        with open(original, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            original_lines = len(f.readlines())\n",
    "        total_paragraphs_original += original_lines\n",
    "    \n",
    "    if os.path.exists(filtered):\n",
    "        with open(filtered, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            filtered_lines = len(f.readlines())\n",
    "        total_paragraphs_filtered += filtered_lines\n",
    "        \n",
    "        print(f\"文件 {i}: {original_lines} → {filtered_lines} 段落 (保留率: {filtered_lines/original_lines*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n总计: {total_paragraphs_original} → {total_paragraphs_filtered} 段落\")\n",
    "print(f\"整体保留率: {total_paragraphs_filtered/total_paragraphs_original*100:.1f}%\")\n",
    "\n",
    "print(f\"\\n🎉 摘要结论专用处理完成！\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ossextractor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
