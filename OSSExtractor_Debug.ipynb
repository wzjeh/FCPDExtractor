{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30dcbcd6",
   "metadata": {},
   "source": [
    "# ğŸ”¬ OSSExtractor è¡¨é¢åˆæˆå‚æ•°æå–å·¥å…· - è°ƒè¯•ç‰ˆæœ¬\n",
    "\n",
    "æœ¬notebookå…è®¸æ‚¨é€æ­¥è°ƒè¯•OSSExtractorçš„æ¯ä¸ªå¤„ç†æ­¥éª¤ï¼ŒæŸ¥çœ‹ä¸­é—´ç»“æœå¹¶ä¼˜åŒ–å‚æ•°ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29deb780",
   "metadata": {},
   "source": [
    "## ğŸ“¦ å¯¼å…¥å¿…è¦çš„åº“å’Œæ¨¡å—\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e4e064e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhaowenyuan/miniconda3/envs/ossextractor/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ‰€æœ‰æ¨¡å—å¯¼å…¥æˆåŠŸï¼\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# æ·»åŠ æ¨¡å—è·¯å¾„\n",
    "sys.path.append('Text Parser')\n",
    "sys.path.append('Text Extraction')\n",
    "\n",
    "# å¯¼å…¥ç»Ÿä¸€çš„å¤„ç†æ¨¡å—\n",
    "from PDF_Unified_Processor import PDFUnifiedProcessor, save_contents_to_specific_folders\n",
    "from TXT_Processing import process_text_file_for_processing\n",
    "from Embedding_and_Similarity import process_text_file_for_embedding\n",
    "from Unified_Text_Processor import (\n",
    "    process_text_file_for_filter,\n",
    "    process_text_file_for_abstract,\n",
    "    process_text_file_for_summerized,\n",
    "    process_text_file_for_filter_meta_llama,\n",
    "    process_text_file_for_abstract_meta_llama,\n",
    "    process_text_file_for_summerized_meta_llama_strict\n",
    ")\n",
    "\n",
    "print(\"âœ… æ‰€æœ‰æ¨¡å—å¯¼å…¥æˆåŠŸï¼\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195375cc",
   "metadata": {},
   "source": [
    "## ğŸ”„ å¤„ç†æµç¨‹è¯´æ˜\n",
    "\n",
    "**OSSExtractorçš„å®Œæ•´å¤„ç†æµç¨‹ï¼š**\n",
    "\n",
    "1. **PDFè½¬æ–‡æœ¬** â†’ åŸå§‹æ–‡æœ¬æ–‡ä»¶\n",
    "2. **æ–‡æœ¬é¢„å¤„ç†** â†’ æ®µè½åˆ†å‰²å’Œè¿‡æ»¤\n",
    "3. **åµŒå…¥ç›¸ä¼¼åº¦ç­›é€‰** â†’ ä»æ‰€æœ‰æ®µè½ä¸­é€‰å‡ºæœ€ç›¸å…³çš„Nä¸ªæ®µè½\n",
    "4. **LLMå†…å®¹è¿‡æ»¤** â†’ ä»ç›¸ä¼¼åº¦ç­›é€‰çš„æ®µè½ä¸­è¿›ä¸€æ­¥ç­›é€‰\n",
    "5. **æŠ½è±¡å’Œæ€»ç»“** â†’ ç”Ÿæˆæœ€ç»ˆçš„ç»“æ„åŒ–å‚æ•°\n",
    "\n",
    "**æ®µè½æ•°é‡å˜åŒ–ç¤ºä¾‹ï¼š**\n",
    "- åŸå§‹æ–‡æœ¬: 100+ æ®µè½\n",
    "- é¢„å¤„ç†å: 50+ æ®µè½  \n",
    "- åµŒå…¥ç­›é€‰å: 20 æ®µè½ (æœ€ç›¸å…³çš„)\n",
    "- LLMè¿‡æ»¤å: 10 æ®µè½ (æœ€ç¬¦åˆè¦æ±‚çš„)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87aff02e",
   "metadata": {},
   "source": [
    "## ğŸ”§ é…ç½®å‚æ•°\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a93a1594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“„ å°†å¤„ç† 1 ä¸ªPDFæ–‡ä»¶:\n",
      "ğŸ“ ä¸»è¾“å‡ºç›®å½•å·²è®¾ç½®ä¸º: /Users/zhaowenyuan/Projects/FCPDExtractor/Data/output\n",
      "----------------------------------------\n",
      "  1. æ­£åœ¨å¤„ç†: 101021acsoprd7b00291.pdf\n",
      "     -> å°†è¾“å‡ºåˆ°: /Users/zhaowenyuan/Projects/FCPDExtractor/Data/output/101021acsoprd7b00291\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# é…ç½®è¦å¤„ç†çš„PDFæ–‡ä»¶\n",
    "pdf_files = [\n",
    "    '/Users/zhaowenyuan/Projects/FCPDExtractor/Data/papers/101021acsoprd7b00291.pdf',\n",
    "    # å¦‚æœæœ‰æ›´å¤šæ–‡ä»¶ï¼Œå¯ä»¥åŠ åœ¨è¿™é‡Œ\n",
    "    # '/Users/zhaowenyuan/Projects/FCPDExtractor/Data/papers/another_paper.pdf',\n",
    "]\n",
    "\n",
    "# å®šä¹‰åŸºç¡€çš„æ•°æ®ç›®å½•\n",
    "base_data_dir = '/Users/zhaowenyuan/Projects/FCPDExtractor/Data'\n",
    "\n",
    "# 1. åœ¨Dataç›®å½•ä¸‹ï¼Œå®šä¹‰ä¸€ä¸ªåä¸º 'output' çš„ä¸»è¾“å‡ºæ–‡ä»¶å¤¹è·¯å¾„\n",
    "main_output_dir = os.path.join(base_data_dir, 'output')\n",
    "\n",
    "# 2. åˆ›å»º 'output' æ–‡ä»¶å¤¹ (å¦‚æœå®ƒä¸å­˜åœ¨çš„è¯)\n",
    "# exist_ok=True è¡¨ç¤ºå¦‚æœæ–‡ä»¶å¤¹å·²å­˜åœ¨ï¼Œåˆ™ä¸ä¼šæŠ¥é”™\n",
    "os.makedirs(main_output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"ğŸ“„ å°†å¤„ç† {len(pdf_files)} ä¸ªPDFæ–‡ä»¶:\")\n",
    "print(f\"ğŸ“ ä¸»è¾“å‡ºç›®å½•å·²è®¾ç½®ä¸º: {main_output_dir}\")\n",
    "print(\"-\" * 40) # æ‰“å°åˆ†å‰²çº¿\n",
    "\n",
    "# éå†æ¯ä¸€ä¸ªè¦å¤„ç†çš„PDFæ–‡ä»¶\n",
    "for i, pdf_path in enumerate(pdf_files, 1):\n",
    "    \n",
    "    # 3. ä»å®Œæ•´è·¯å¾„ä¸­è·å–PDFçš„æ–‡ä»¶å (ä¾‹å¦‚: 'd2cp03073j.pdf')\n",
    "    pdf_filename = os.path.basename(pdf_path)\n",
    "    \n",
    "    # 4. å»æ‰.pdfæ‰©å±•åï¼Œåˆ›å»ºæ–‡ä»¶å¤¹å (ä¾‹å¦‚: 'd2cp03073j')\n",
    "    folder_name = os.path.splitext(pdf_filename)[0]\n",
    "    \n",
    "    # 5. æ‹¼æ¥å‡ºè¿™ä¸ªPDFä¸“å±çš„è¾“å‡ºæ–‡ä»¶å¤¹çš„å®Œæ•´è·¯å¾„\n",
    "    specific_output_dir = os.path.join(main_output_dir, folder_name)\n",
    "    \n",
    "    # 6. åˆ›å»ºè¿™ä¸ªä¸“å±çš„æ–‡ä»¶å¤¹\n",
    "    os.makedirs(specific_output_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"  {i}. æ­£åœ¨å¤„ç†: {pdf_filename}\")\n",
    "    print(f\"     -> å°†è¾“å‡ºåˆ°: {specific_output_dir}\")\n",
    "\n",
    "    # --- åœ¨è¿™é‡Œæ¥ä¸Šä½ åç»­çš„å¤„ç†é€»è¾‘ ---\n",
    "    # ä¾‹å¦‚ï¼Œä½ ä¹‹åæ‰€æœ‰ä¿å­˜æ–‡ä»¶çš„æ“ä½œï¼Œéƒ½åº”è¯¥ä½¿ç”¨ `specific_output_dir` ä½œä¸ºè·¯å¾„\n",
    "    # processed_text_path = os.path.join(specific_output_dir, 'Processed_text.txt')\n",
    "    # with open(processed_text_path, 'w') as f:\n",
    "    #     f.write(\"è¿™é‡Œæ˜¯å¤„ç†åçš„æ–‡æœ¬\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4eb3a6",
   "metadata": {},
   "source": [
    "## ğŸ“„ æ­¥éª¤ 1: PDFè½¬æ–‡æœ¬å¤„ç†\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a110213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ æ­¥éª¤ 1/5: PDFè½¬æ–‡æœ¬å¤„ç†...\n",
      "==================================================\n",
      "âœ… PDFè½¬æ–‡æœ¬å®Œæˆï¼ç”Ÿæˆäº† 1 ä¸ªæ–‡æœ¬æ–‡ä»¶:\n",
      "  1. /Users/zhaowenyuan/Projects/FCPDExtractor/Data/output/101021acsoprd7b00291/101021acsoprd7b00291.txt\n",
      "     ğŸ“Š è¡Œæ•°: 731\n",
      "     ğŸ“ æ–‡ä»¶å¤§å°: 33175 bytes\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸš€ æ­¥éª¤ 1/5: PDFè½¬æ–‡æœ¬å¤„ç†...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# ä½¿ç”¨ç»Ÿä¸€çš„PDFå¤„ç†æ¨¡å—\n",
    "processor = PDFUnifiedProcessor()\n",
    "\n",
    "# æ‰§è¡ŒPDFè½¬æ–‡æœ¬\n",
    "output_files = save_contents_to_specific_folders(pdf_files, main_output_dir)\n",
    "\n",
    "print(f\"âœ… PDFè½¬æ–‡æœ¬å®Œæˆï¼ç”Ÿæˆäº† {len(output_files)} ä¸ªæ–‡æœ¬æ–‡ä»¶:\")\n",
    "for i, file in enumerate(output_files, 1):\n",
    "    print(f\"  {i}. {file}\")\n",
    "    \n",
    "    # æ˜¾ç¤ºæ–‡ä»¶å¤§å°å’Œè¡Œæ•°\n",
    "    if os.path.exists(file):\n",
    "        with open(file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            lines = f.readlines()\n",
    "            print(f\"     ğŸ“Š è¡Œæ•°: {len(lines)}\")\n",
    "            print(f\"     ğŸ“ æ–‡ä»¶å¤§å°: {os.path.getsize(file)} bytes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d163864",
   "metadata": {},
   "source": [
    "### ğŸ” æŸ¥çœ‹PDFè½¬æ–‡æœ¬ç»“æœ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "383ac1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“– æŸ¥çœ‹æ–‡ä»¶: 101021acsoprd7b00291.txt\n",
      "==================================================\n",
      "ğŸ“Š æ€»å­—ç¬¦æ•°: 32660\n",
      "ğŸ“Š æ€»è¡Œæ•°: 731\n",
      "\n",
      "ğŸ“„ å‰500ä¸ªå­—ç¬¦é¢„è§ˆ:\n",
      "------------------------------\n",
      "Process Development and Scale-up of the Continuous Flow Nitration\n",
      "of Triï¬‚uoromethoxybenzene\n",
      "Zhenghui Wen,â€ ,â€¡ Fengjun Jiao,â€  Mei Yang,â€  Shuainan Zhao,â€ ,â€¡ Feng Zhou,â€ ,â€¡ and Guangwen Chen*,â€ \n",
      "â€ Dalian National Laboratory for Clean Energy, Dalian Institute of Chemical Physics, Chinese Academy of Sciences, Dalian 116023,\n",
      "China\n",
      "â€¡University of Chinese Academy of Sciences, Beijing 100049, China\n",
      "*\n",
      "S Supporting Information\n",
      "ABSTRACT: In this work, continuous ï¬‚ow nitration of triï¬‚uoromethoxybenzene (TFMB) was...\n"
     ]
    }
   ],
   "source": [
    "# é€‰æ‹©ç¬¬ä¸€ä¸ªæ–‡ä»¶è¿›è¡Œè¯¦ç»†æŸ¥çœ‹\n",
    "sample_file = output_files[0]\n",
    "print(f\"ğŸ“– æŸ¥çœ‹æ–‡ä»¶: {os.path.basename(sample_file)}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "with open(sample_file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "    content = f.read()\n",
    "    \n",
    "print(f\"ğŸ“Š æ€»å­—ç¬¦æ•°: {len(content)}\")\n",
    "print(f\"ğŸ“Š æ€»è¡Œæ•°: {len(content.splitlines())}\")\n",
    "print(\"\\nğŸ“„ å‰500ä¸ªå­—ç¬¦é¢„è§ˆ:\")\n",
    "print(\"-\" * 30)\n",
    "print(content[:500] + \"...\" if len(content) > 500 else content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c90caea",
   "metadata": {},
   "source": [
    "### ğŸ” ç»“æ„åŒ–PDFè§£æï¼ˆå¯é€‰ï¼‰\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a2aae9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ç»“æ„åŒ–PDFè§£æï¼ˆé’ˆå¯¹æ‘˜è¦å’Œç»“è®ºï¼‰\n",
      "==================================================\n",
      "\n",
      "ğŸ“„ å¤„ç†æ–‡ä»¶ 1/1: 101021acsoprd7b00291.pdf\n",
      "âœ… other ç« èŠ‚: 8 ä¸ªæ®µè½ -> /Users/zhaowenyuan/Projects/FCPDExtractor/Data/output/101021acsoprd7b00291/101021acsoprd7b00291_other.txt\n",
      "  âœ… other: 663 ä¸ªæ®µè½\n",
      "\n",
      "ğŸ‰ ç»“æ„åŒ–è§£æå®Œæˆï¼\n"
     ]
    }
   ],
   "source": [
    "# å¯é€‰ï¼šä½¿ç”¨ç»“æ„åŒ–è§£ææå–æ‘˜è¦å’Œç»“è®ºéƒ¨åˆ†\n",
    "print(\"ğŸ” ç»“æ„åŒ–PDFè§£æï¼ˆé’ˆå¯¹æ‘˜è¦å’Œç»“è®ºï¼‰\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "structured_results = []\n",
    "\n",
    "for i, pdf_path in enumerate(pdf_files, 1):\n",
    "    print(f\"\\nğŸ“„ å¤„ç†æ–‡ä»¶ {i}/{len(pdf_files)}: {os.path.basename(pdf_path)}\")\n",
    "    \n",
    "    # ä½¿ç”¨ç»Ÿä¸€å¤„ç†å™¨è¿›è¡Œç»“æ„åŒ–è§£æ\n",
    "    result = processor.process_pdf_comprehensive(pdf_path, main_output_dir, mode='structured')\n",
    "    structured_results.append(result)\n",
    "    \n",
    "    # æ˜¾ç¤ºç»“æœ\n",
    "    for section, file_path in result.items():\n",
    "        if os.path.exists(file_path):\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                lines = f.readlines()\n",
    "            print(f\"  âœ… {section}: {len(lines)} ä¸ªæ®µè½\")\n",
    "\n",
    "print(f\"\\nğŸ‰ ç»“æ„åŒ–è§£æå®Œæˆï¼\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8c6cf3",
   "metadata": {},
   "source": [
    "## ğŸ“ æ­¥éª¤ 2: æ–‡æœ¬é¢„å¤„ç†\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab72e5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ æ­¥éª¤ 2/5: æ–‡æœ¬é¢„å¤„ç†...\n",
      "==================================================\n",
      "\n",
      "ğŸ“„ å¤„ç†æ–‡ä»¶ 1/1: 101021acsoprd7b00291.txt\n",
      "  âœ… é¢„å¤„ç†å®Œæˆï¼Œè¿‡æ»¤äº† 34 ä¸ªæ®µè½\n",
      "  ğŸ“ è¾“å‡ºæ–‡ä»¶: /Users/zhaowenyuan/Projects/FCPDExtractor/Data/output/101021acsoprd7b00291/Processed_101021acsoprd7b00291.txt\n",
      "\n",
      "ğŸ‰ æ–‡æœ¬é¢„å¤„ç†å®Œæˆï¼æ€»å…±è¿‡æ»¤äº† 34 ä¸ªæ®µè½\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸš€ æ­¥éª¤ 2/5: æ–‡æœ¬é¢„å¤„ç†...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "total_filtered_count = 0\n",
    "processed_files = []\n",
    "\n",
    "# å¤„ç†ä¸Šä¸€æ­¥ç”Ÿæˆçš„TXTæ–‡ä»¶ï¼Œè€Œä¸æ˜¯PDFæ–‡ä»¶\n",
    "for i, txt_file in enumerate(output_files, 1):\n",
    "    print(f\"\\nğŸ“„ å¤„ç†æ–‡ä»¶ {i}/{len(output_files)}: {os.path.basename(txt_file)}\")\n",
    "    \n",
    "    # æ‰§è¡Œæ–‡æœ¬é¢„å¤„ç† - å¤„ç†TXTæ–‡ä»¶\n",
    "    processed_file_path, filtered_count = process_text_file_for_processing(txt_file)\n",
    "    processed_files.append(processed_file_path)\n",
    "    total_filtered_count += filtered_count\n",
    "    \n",
    "    print(f\"  âœ… é¢„å¤„ç†å®Œæˆï¼Œè¿‡æ»¤äº† {filtered_count} ä¸ªæ®µè½\")\n",
    "    print(f\"  ğŸ“ è¾“å‡ºæ–‡ä»¶: {processed_file_path}\")\n",
    "\n",
    "print(f\"\\nğŸ‰ æ–‡æœ¬é¢„å¤„ç†å®Œæˆï¼æ€»å…±è¿‡æ»¤äº† {total_filtered_count} ä¸ªæ®µè½\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dab9779",
   "metadata": {},
   "source": [
    "### ğŸ” æŸ¥çœ‹é¢„å¤„ç†ç»“æœ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8664887d",
   "metadata": {},
   "source": [
    "### ğŸ’¡ LLMå†…å®¹è¿‡æ»¤è¯´æ˜\n",
    "\n",
    "**è¿™ä¸€æ­¥çš„ä½œç”¨ï¼š**\n",
    "- è¾“å…¥ï¼šåµŒå…¥ç›¸ä¼¼åº¦ç­›é€‰å‡ºçš„æ®µè½ï¼ˆå¦‚20ä¸ªæ®µè½ï¼‰\n",
    "- å¤„ç†ï¼šä½¿ç”¨Nous-Hermes-Llama2-13Bæ¨¡å‹åˆ¤æ–­æ¯ä¸ªæ®µè½æ˜¯å¦çœŸæ­£ä¸è¡¨é¢åŒ–å­¦ååº”ç›¸å…³\n",
    "- è¾“å‡ºï¼šè¿›ä¸€æ­¥ç­›é€‰çš„ç›¸å…³æ®µè½ï¼ˆå¦‚10ä¸ªæ®µè½ï¼‰\n",
    "\n",
    "**æ¨¡å‹é€‰æ‹©ï¼š**\n",
    "- ä¼˜å…ˆä½¿ç”¨ï¼šNous-Hermes-Llama2-13B-Instructï¼ˆæ›´æ™ºèƒ½ï¼Œæ€§èƒ½æ›´å¥½ï¼‰\n",
    "- å›é€€æ¨¡å‹ï¼šnous-hermes-llama2-13bï¼ˆç¨³å®šå¯é ï¼‰\n",
    "\n",
    "**ä¸ºä»€ä¹ˆæ®µè½æ•°ä¼šå‡å°‘ï¼š**\n",
    "- åµŒå…¥ç›¸ä¼¼åº¦åªæ˜¯åŸºäºå…³é”®è¯åŒ¹é…\n",
    "- LLMè¿‡æ»¤ä¼šè¿›è¡Œæ›´æ™ºèƒ½çš„å†…å®¹ç†è§£\n",
    "- æœ€ç»ˆä¿ç•™çœŸæ­£ç›¸å…³çš„æ®µè½\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40a707c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” åˆ†ææ–‡ä»¶: 101021acsoprd7b00291.txt\n",
      "==================================================\n",
      "ğŸ“Š åŸå§‹æ–‡ä»¶æ€»è¡Œæ•°: 731\n",
      "ğŸ“Š ç©ºè¡Œæ•°é‡: 43\n",
      "ğŸ“Š åˆ†å‰²åçš„æ®µè½æ•°: 43\n",
      "ğŸ“Š å¹³å‡æ®µè½é•¿åº¦: 756.1 å­—ç¬¦\n",
      "\n",
      "ğŸ“„ å‰5ä¸ªæ®µè½é¢„è§ˆ:\n",
      "------------------------------\n",
      "æ®µè½ 1 (é•¿åº¦: 1160): Process Development and Scale-up of the Continuous Flow Nitration of Triï¬‚uoromethoxybenzene Zhenghui Wen,â€ ,â€¡ Fengjun Jiao,â€  Mei Yang,â€  Shuainan Zhao,â€ ...\n",
      "æ®µè½ 2 (é•¿åº¦: 932): Triï¬‚uoromethoxy aniline is an important intermediate involved in the synthesis of a wide range of ï¬ne chemicals, for example, pesticides,1 pharmaceuti...\n",
      "æ®µè½ 3 (é•¿åº¦: 969): Therefore, it is very important and urgent to develop a new strategy based on process intensiï¬cation technology to improve the productivity and proces...\n",
      "æ®µè½ 4 (é•¿åº¦: 926): Brocklehurst et al.8 used a commercially available continuous ï¬‚ow reactor to perform the challenging nitration of 2-amino-4-bromobenzoic acid methyl e...\n",
      "æ®µè½ 5 (é•¿åº¦: 1006): Therefore, the selectivity of m- NB and DNB should be controlled as low as possible to cut the cost of the separation. The objective was to minimize t...\n",
      "\n",
      "ğŸ“Š æ€»ç»“:\n",
      "  - åŸå§‹æ–‡ä»¶è¡Œæ•°: 43\n",
      "  - é¢„å¤„ç†åæ®µè½æ•°: 25\n",
      "  - è¿‡æ»¤æ‰çš„æ®µè½æ•°: 18\n",
      "  - ä¿ç•™æ¯”ä¾‹: 58.1%\n"
     ]
    }
   ],
   "source": [
    "# è¯¦ç»†åˆ†ææ®µè½åˆ†å‰²è¿‡ç¨‹\n",
    "def analyze_paragraph_segmentation(txt_file):\n",
    "    print(f\"ğŸ” åˆ†ææ–‡ä»¶: {os.path.basename(txt_file)}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    with open(txt_file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    print(f\"ğŸ“Š åŸå§‹æ–‡ä»¶æ€»è¡Œæ•°: {len(lines)}\")\n",
    "    \n",
    "    # æ¨¡æ‹Ÿæ®µè½åˆ†å‰²è¿‡ç¨‹\n",
    "    current_segment = []\n",
    "    segments = []\n",
    "    empty_lines_count = 0\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        if line.strip():  # éç©ºè¡Œ\n",
    "            current_segment.append(line.strip())\n",
    "        else:  # ç©ºè¡Œ\n",
    "            empty_lines_count += 1\n",
    "            if current_segment:  # å¦‚æœå½“å‰æ®µè½ä¸ä¸ºç©º\n",
    "                segments.append(' '.join(current_segment))\n",
    "                current_segment = []\n",
    "    \n",
    "    # å¤„ç†æœ€åä¸€ä¸ªæ®µè½\n",
    "    if current_segment:\n",
    "        segments.append(' '.join(current_segment))\n",
    "    \n",
    "    print(f\"ğŸ“Š ç©ºè¡Œæ•°é‡: {empty_lines_count}\")\n",
    "    print(f\"ğŸ“Š åˆ†å‰²åçš„æ®µè½æ•°: {len(segments)}\")\n",
    "    print(f\"ğŸ“Š å¹³å‡æ®µè½é•¿åº¦: {sum(len(seg) for seg in segments) / len(segments):.1f} å­—ç¬¦\")\n",
    "    \n",
    "    print(\"\\nğŸ“„ å‰5ä¸ªæ®µè½é¢„è§ˆ:\")\n",
    "    print(\"-\" * 30)\n",
    "    for i, segment in enumerate(segments[:5]):\n",
    "        print(f\"æ®µè½ {i+1} (é•¿åº¦: {len(segment)}): {segment[:150]}...\" if len(segment) > 150 else f\"æ®µè½ {i+1} (é•¿åº¦: {len(segment)}): {segment}\")\n",
    "    \n",
    "    return segments\n",
    "\n",
    "# åˆ†æåŸå§‹TXTæ–‡ä»¶çš„æ®µè½åˆ†å‰²\n",
    "if output_files:\n",
    "    original_segments = analyze_paragraph_segmentation(output_files[0])\n",
    "    \n",
    "    print(f\"\\nğŸ“Š æ€»ç»“:\")\n",
    "    print(f\"  - åŸå§‹æ–‡ä»¶è¡Œæ•°: {len(original_segments)}\")\n",
    "    print(f\"  - é¢„å¤„ç†åæ®µè½æ•°: 25\")\n",
    "    print(f\"  - è¿‡æ»¤æ‰çš„æ®µè½æ•°: {len(original_segments) - 25}\")\n",
    "    print(f\"  - ä¿ç•™æ¯”ä¾‹: {25/len(original_segments)*100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6b4595",
   "metadata": {},
   "source": [
    "## ğŸ” æ­¥éª¤ 3: åµŒå…¥å’Œç›¸ä¼¼åº¦è®¡ç®—\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1d9b5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ æ­¥éª¤ 3/5: åµŒå…¥å’Œç›¸ä¼¼åº¦è®¡ç®—...\n",
      "==================================================\n",
      "\n",
      "ğŸ“„ å¤„ç†æ–‡ä»¶ 1/1: Processed_101021acsoprd7b00291.txt\n",
      "  âœ… åµŒå…¥å’Œç›¸ä¼¼åº¦è®¡ç®—å®Œæˆ\n",
      "  ğŸ“ è¾“å‡ºæ–‡ä»¶: /Users/zhaowenyuan/Projects/FCPDExtractor/Data/output/101021acsoprd7b00291/Embedding_101021acsoprd7b00291.txt\n",
      "\n",
      "ğŸ‰ åµŒå…¥å’Œç›¸ä¼¼åº¦è®¡ç®—å®Œæˆï¼\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸš€ æ­¥éª¤ 3/5: åµŒå…¥å’Œç›¸ä¼¼åº¦è®¡ç®—...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "embedding_files = []\n",
    "\n",
    "# ä½¿ç”¨ä¸Šä¸€æ­¥é¢„å¤„ç†åçš„æ–‡ä»¶\n",
    "for i, processed_file in enumerate(processed_files, 1):\n",
    "    print(f\"\\nğŸ“„ å¤„ç†æ–‡ä»¶ {i}/{len(processed_files)}: {os.path.basename(processed_file)}\")\n",
    "    \n",
    "    # æ‰§è¡ŒåµŒå…¥å’Œç›¸ä¼¼åº¦è®¡ç®—\n",
    "    embedding_file_path = process_text_file_for_embedding(processed_file)\n",
    "    embedding_files.append(embedding_file_path)\n",
    "    \n",
    "    print(f\"  âœ… åµŒå…¥å’Œç›¸ä¼¼åº¦è®¡ç®—å®Œæˆ\")\n",
    "    print(f\"  ğŸ“ è¾“å‡ºæ–‡ä»¶: {embedding_file_path}\")\n",
    "\n",
    "print(f\"\\nğŸ‰ åµŒå…¥å’Œç›¸ä¼¼åº¦è®¡ç®—å®Œæˆï¼\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f572a33b",
   "metadata": {},
   "source": [
    "### ğŸ” æŸ¥çœ‹åµŒå…¥ç»“æœ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0bc8271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“– æŸ¥çœ‹åµŒå…¥æ–‡ä»¶: Embedding_101021acsoprd7b00291.txt\n",
      "==================================================\n",
      "ğŸ“Š åµŒå…¥ç›¸ä¼¼åº¦ç­›é€‰åæ®µè½æ•°: 20\n",
      "\n",
      "ğŸ“„ ç›¸ä¼¼åº¦æœ€é«˜çš„æ®µè½é¢„è§ˆ:\n",
      "------------------------------\n",
      "æ®µè½ 1: The general laboratory process developments were carried out in microchannel reactors. TFMB (7.57 M, ï¬‚ow rate of 0.4âˆ’1.0 mLÂ·minâˆ’1) and a solution of fuming nitric acid in concentrated sulfuric acid (2...\n",
      "æ®µè½ 3: A faster ï¬‚ow rate would result in a better mixing eï¬€ect, which can make the organic compound more evenly dispersed in the acid phase. Besides, a faster ï¬‚ow rate would also decrease the residence time....\n"
     ]
    }
   ],
   "source": [
    "# æŸ¥çœ‹åµŒå…¥ç»“æœ\n",
    "sample_embedding = embedding_files[0]\n",
    "print(f\"ğŸ“– æŸ¥çœ‹åµŒå…¥æ–‡ä»¶: {os.path.basename(sample_embedding)}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "with open(sample_embedding, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "print(f\"ğŸ“Š åµŒå…¥ç›¸ä¼¼åº¦ç­›é€‰åæ®µè½æ•°: {len(lines)}\")\n",
    "print(\"\\nğŸ“„ ç›¸ä¼¼åº¦æœ€é«˜çš„æ®µè½é¢„è§ˆ:\")\n",
    "print(\"-\" * 30)\n",
    "for i, line in enumerate(lines[:3]):\n",
    "    if line.strip():\n",
    "        print(f\"æ®µè½ {i+1}: {line[:200]}...\" if len(line) > 200 else f\"æ®µè½ {i+1}: {line}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4860a8f4",
   "metadata": {},
   "source": [
    "## ğŸ¤– æ­¥éª¤ 4: LLMå†…å®¹è¿‡æ»¤\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9af29236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ æ­¥éª¤ 4/5: LLMå†…å®¹è¿‡æ»¤...\n",
      "==================================================\n",
      "\n",
      "ğŸ“„ å¤„ç†æ–‡ä»¶ 1/1: Embedding_101021acsoprd7b00291.txt\n",
      "ğŸ” å°è¯•åŠ è½½æ¨¡å‹ï¼Œè·¯å¾„: /Users/zhaowenyuan/Projects/FCPDExtractor/models\n",
      "âœ… æˆåŠŸåŠ è½½ nous-hermes-llama2-13b.Q4_0.gguf æ¨¡å‹\n",
      "ğŸ” å¤„ç†æ–‡ä»¶: Embedding_101021acsoprd7b00291.txt\n",
      "==================================================\n",
      "ğŸ“Š åŸå§‹æ®µè½æ•°: 10\n",
      "\n",
      "ğŸ¤– æ­¥éª¤1: LLMå†…å®¹è¿‡æ»¤...\n",
      "...å¼€å§‹ä½¿ç”¨LLMè¿›è¡Œæ®µè½åˆ†ç±»...\n",
      "...åˆ†ç±»å®Œæˆï¼Œä¿ç•™ 10 ä¸ªç›¸å…³æ®µè½ã€‚\n",
      "âœ… è¿‡æ»¤åæ®µè½æ•°: 10\n",
      "  âœ… LLMå†…å®¹è¿‡æ»¤å®Œæˆ\n",
      "  ğŸ“ è¾“å‡ºæ–‡ä»¶: /Users/zhaowenyuan/Projects/FCPDExtractor/Data/output/101021acsoprd7b00291/Embedding_101021acsoprd7b00291_Filtered.txt\n",
      "\n",
      "ğŸ‰ LLMå†…å®¹è¿‡æ»¤å®Œæˆï¼\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸš€ æ­¥éª¤ 4/5: LLMå†…å®¹è¿‡æ»¤...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "filter_files = []\n",
    "\n",
    "for i, embedding_file in enumerate(embedding_files, 1):\n",
    "    print(f\"\\nğŸ“„ å¤„ç†æ–‡ä»¶ {i}/{len(embedding_files)}: {os.path.basename(embedding_file)}\")\n",
    "    \n",
    "    # æ‰§è¡ŒLLMå†…å®¹è¿‡æ»¤\n",
    "    filter_file_path = process_text_file_for_filter(embedding_file)\n",
    "    filter_files.append(filter_file_path)\n",
    "    \n",
    "    print(f\"  âœ… LLMå†…å®¹è¿‡æ»¤å®Œæˆ\")\n",
    "    print(f\"  ğŸ“ è¾“å‡ºæ–‡ä»¶: {filter_file_path}\")\n",
    "    \n",
    "kept = sum(1 for _ in open(filter_files[-1], 'r', encoding='utf-8', errors='ignore') if _.strip())\n",
    "if kept == 0:\n",
    "    print(\"âš ï¸ è¿‡æ»¤ä¸ºç©ºï¼Œå›é€€ç”¨åµŒå…¥Top-N\")\n",
    "    filter_files[-1] = embedding_files[-1]\n",
    "\n",
    "print(f\"\\nğŸ‰ LLMå†…å®¹è¿‡æ»¤å®Œæˆï¼\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4522a3d6",
   "metadata": {},
   "source": [
    "### ğŸ” æŸ¥çœ‹LLMè¿‡æ»¤ç»“æœ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4def142c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“– æŸ¥çœ‹è¿‡æ»¤æ–‡ä»¶: Embedding_101021acsoprd7b00291_Filtered.txt\n",
      "==================================================\n",
      "ğŸ“Š LLMè¿‡æ»¤åæ®µè½æ•°: 20\n",
      "\n",
      "ğŸ“„ è¿‡æ»¤åçš„æ®µè½é¢„è§ˆ:\n",
      "------------------------------\n",
      "æ®µè½ 1: The general laboratory process developments were carried out in microchannel reactors. TFMB (7.57 M, ï¬‚ow rate of 0.4âˆ’1.0 mLÂ·minâˆ’1) and a solution of fuming nitric acid in concentrated sulfuric acid (2...\n",
      "æ®µè½ 3: A faster ï¬‚ow rate would result in a better mixing eï¬€ect, which can make the organic compound more evenly dispersed in the acid phase. Besides, a faster ï¬‚ow rate would also decrease the residence time....\n"
     ]
    }
   ],
   "source": [
    "# æŸ¥çœ‹LLMè¿‡æ»¤ç»“æœ\n",
    "sample_filter = filter_files[0]\n",
    "print(f\"ğŸ“– æŸ¥çœ‹è¿‡æ»¤æ–‡ä»¶: {os.path.basename(sample_filter)}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "with open(sample_filter, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "print(f\"ğŸ“Š LLMè¿‡æ»¤åæ®µè½æ•°: {len(lines)}\")\n",
    "print(\"\\nğŸ“„ è¿‡æ»¤åçš„æ®µè½é¢„è§ˆ:\")\n",
    "print(\"-\" * 30)\n",
    "for i, line in enumerate(lines[:3]):\n",
    "    if line.strip():\n",
    "        print(f\"æ®µè½ {i+1}: {line[:200]}...\" if len(line) > 200 else f\"æ®µè½ {i+1}: {line}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcd10843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STRICT = meta-llama-3.1-8b-instruct-q4_k_m-2.gguf\n"
     ]
    }
   ],
   "source": [
    "# 1) è®¾ç½®ä¸¥æ ¼æ¨¡å‹ååˆ°ä½ æ–°ä¸‹çš„æœ¬åœ°æ–‡ä»¶\n",
    "import os, importlib\n",
    "os.environ[\"FCPD_STRICT_MODEL_NAME\"] = \"meta-llama-3.1-8b-instruct-q4_k_m-2.gguf\"\n",
    "print(\"STRICT =\", os.getenv(\"FCPD_STRICT_MODEL_NAME\"))\n",
    "\n",
    "# 2) å¼ºåˆ¶é‡è½½æ¨¡å—ï¼Œå¹¶é‡æ–°å¯¼å…¥å‡½æ•°ï¼Œé¿å…ç”¨åˆ°æ—§ç‰ˆæœ¬\n",
    "import Unified_Text_Processor as UTP\n",
    "importlib.reload(UTP)\n",
    "from Unified_Text_Processor import process_text_file_for_summerized\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88626257",
   "metadata": {},
   "source": [
    "## ğŸ“Š æ­¥éª¤ 5: æŠ½è±¡å’Œæ€»ç»“\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a11b502a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ æ­¥éª¤ 5/5: æŠ½è±¡å’Œæ€»ç»“...\n",
      "==================================================\n",
      "\n",
      "ğŸ“„ å¤„ç†æ–‡ä»¶ 1/1: Embedding_101021acsoprd7b00291_Filtered.txt\n",
      "  â³  æ­£åœ¨æ‰§è¡Œ [æŠ½è±¡]...\n",
      "ğŸ” å°è¯•åŠ è½½æ¨¡å‹ï¼Œè·¯å¾„: /Users/zhaowenyuan/Projects/FCPDExtractor/models\n",
      "âœ… æˆåŠŸåŠ è½½ nous-hermes-llama2-13b.Q4_0.gguf æ¨¡å‹\n",
      "ğŸ” å¤„ç†æ–‡ä»¶: Embedding_101021acsoprd7b00291_Filtered.txt\n",
      "==================================================\n",
      "ğŸ“Š åŸå§‹æ®µè½æ•°: 10\n",
      "\n",
      "ğŸ“ æ­¥éª¤2: æ–‡æœ¬æŠ½è±¡...\n",
      "Abstract 1/10:\n",
      "The general laboratory process developments were carried out in microchannel reactors. TFMB (7.57 M, ï¬‚ow rate of 0.4âˆ’1.0 mLÂ·minâˆ’1) and a solution of fuming nitric acid in concentrated sulfuric acid (2.49âˆ’3.19 M, ï¬‚ow rate of 0.8âˆ’ 2.2 mLÂ·minâˆ’1) were delivered by two syringe pumps (TYD01- 02, Lead Fluid), respectively. The ï¬‚uids reacted in capillaries with a length deï¬ned by the desired residence tim\n",
      "Abstract 2/10:\n",
      "A faster ï¬‚ow rate would result in a better mixing eï¬€ect, which can make the organic compound more evenly dispersed in the acid phase. Besides, a faster ï¬‚ow rate would also decrease the residence time. Therefore, a faster ï¬‚ow rate could reduce the occurrence of dinitration. 2.1.6. Eï¬€ect of Reactor Structure. Considering that the nitration processes were limited by the mass transfer in microchannel \n",
      "Abstract 3/10:\n",
      "TFMB (7.57 M, ï¬‚ow rate of 10âˆ’20 mLÂ·minâˆ’1) and a solution of fuming nitric acid in concentrated sulfuric acid (3.19 M, ï¬‚ow rate of 24âˆ’39 mLÂ·minâˆ’1) were pumped into microreactor by two metering pumps (P1, P2, SSI, USA), respectively. The temperature of the microreactor was controlled by the microchannel heat exchanger which is integrated in the microreactor system. Then the mixed solution was introd\n",
      "Abstract 4/10:\n",
      "The highest conversion (99.6%) of reactant was obtained in the microchannel coupled with tubular reactor system at the condition of N/S = 0.25, N/F = 1.1, Ï† = 97 wt %, T = 273 K, Qor = 0.4 mLÂ·minâˆ’1, and Qaq = 0.9 mLÂ· minâˆ’1, with the selectivity of o-NB, m-NB, p-NB, and DNB being 7.26%, 0.08%, 90.97%, and 1.04%, respectively. Encouraged by the lab-scale results, the scale-up of the nitration of TFM\n",
      "Abstract 5/10:\n",
      "Process Development and Scale-up of the Continuous Flow Nitration of Triï¬‚uoromethoxybenzene Zhenghui Wen,â€ ,â€¡ Fengjun Jiao,â€  Mei Yang,â€  Shuainan Zhao,â€ ,â€¡ Feng Zhou,â€ ,â€¡ and Guangwen Chen*,â€  â€ Dalian National Laboratory for Clean Energy, Dalian Institute of Chemical Physics, Chinese Academy of Sciences, Dalian 116023, China â€¡University of Chinese Academy of Sciences, Beijing 100049, China * S Supporti\n",
      "Abstract 6/10:\n",
      "The quartz sand microparticles with an average size of 710 Î¼m were packed in the tubular reactor at a porosity of 0.39. It is observed from Figure 7a that TFMB is totally converted at the low ï¬‚ow rate and then the conversion decreases directly with the increasing ï¬‚ow rate. Given such a low volume of the microreactor system, multiply increasing ï¬‚ow rates lead to a shorter residence time which is no\n",
      "Abstract 7/10:\n",
      "with the conversion of TFMB being 99.6%. The results showed that the microreactor coupled with distributed packed tubular reactor could conduct the continuous ï¬‚ow nitration of TFMB well with a good performance. The precise control of temperature distribution and the eï¬ƒcient mixing in micro- reactor ensured the nitration reaction proceeded at a fast rate and minimized the formation of the byproduct\n",
      "Abstract 8/10:\n",
      "Therefore, the selectivity of m- NB and DNB should be controlled as low as possible to cut the cost of the separation. The objective was to minimize the byproduct selectivity (m-NB < 0.1%, DNB < 1.5%) without decline of the product yield, which could bring signiï¬cant economic beneï¬ts in saving costs of downstream separation and products puriï¬cation. First, the eï¬€ects of process parameters on the c\n",
      "Abstract 9/10:\n",
      "The mixture then ï¬‚owed through the microreactor which was cooled by running water. After the quick mixing in microreactor Figure 7. Eï¬€ect of ï¬‚ow rate on the (a) conversion of TFMB and (b, c) product selectivity in a packed microchannel system. N/S = 0.25, N/F = 1.1, Ï† = 97 wt %, T = 273 K. Organic Process Research & Development Article DOI: 10.1021/acs.oprd.7b00291 Org. Process Res. Dev. 2017, 21,\n",
      "Abstract 10/10:\n",
      "91.08% of p-NB, 7.05% of o-NB, and only trace of m-NB (0.08%) and DNB (1.34%) were obtained, Figure 8. Schematic setup of strategy A for the scale up of the continuous ï¬‚ow TFMB nitration. (a) 3D model of setup of strategy A (b) cutaway picture of packed tubular reactor (red blocks represent packed microparticles). Table 1. Screen of the Size of the Packed Particle on the Scale up of the Continuous\n",
      "  âœ… æŠ½è±¡å®Œæˆ: Embedding_101021acsoprd7b00291_Filtered_Abstract.txt\n",
      "  â³  æ­£åœ¨æ‰§è¡Œ [æ€»ç»“]...\n",
      "ğŸ” å°è¯•åŠ è½½æ¨¡å‹ï¼Œè·¯å¾„: /Users/zhaowenyuan/Projects/FCPDExtractor/models\n",
      "ğŸ”’ ä¸¥æ ¼æ¨¡å¼ï¼Œç›®æ ‡æ¨¡å‹: meta-llama-3.1-8b-instruct-q4_k_m-2.gguf\n",
      "âœ… æˆåŠŸåŠ è½½(ä¸¥æ ¼, æœ¬åœ°modelsç›®å½•) meta-llama-3.1-8b-instruct-q4_k_m-2.gguf æ¨¡å‹\n",
      "ğŸ” å¤„ç†æ–‡ä»¶: Embedding_101021acsoprd7b00291_Filtered_Abstract.txt\n",
      "==================================================\n",
      "ğŸ“Š åŸå§‹æ®µè½æ•°: 10\n",
      "\n",
      "ğŸ“Š æ­¥éª¤3: å‚æ•°æ€»ç»“...\n",
      "ğŸ”¥ Warmup output: [ \n",
      "\n",
      "(Note: This paragraph does not contain] (len=41)\n",
      "ğŸ”¥ Summarize warmup passed.\n",
      "Summarized 1/10:\n",
      "### Step-by-Step Solution ###\n",
      "\n",
      "## Step 1: Identify the reaction type\n",
      "The paragraph does not explicitly mention a specific chemical reaction or process beyond mentioning it as part of general laboratory process developments. Therefore, we will leave this field blank.\n",
      "\n",
      "## Step 2: Extract reactants and their roles\n",
      "From the text, two substances are mentioned:\n",
      "- TFMB (7.57 M) delivered by one syringe pump.\n",
      "- A solution of fuming nitric acid in concentrated sulfuric acid (2.49âˆ’3.19 M), also delivered by a separate syringe pump.\n",
      "\n",
      "Given that both are involved in reacting within capillaries, we can infer they act as reactants but cannot determine their roles without further context or information on the reaction type.\n",
      "\n",
      "## Step 3: Extract products and yields\n",
      "There is no mention of specific chemical products formed from this process. Therefore, we will leave these fields blank for now.\n",
      "\n",
      "## Step 4: Determine conditions\n",
      "- Temperature: Not explicitly mentioned.\n",
      "- Residence Time: The length of capillaries was defined by the desired residence time but not specified in units or value.\n",
      "- Flow Rate:\n",
      "    - For TFMB (reactant A): Given as a range, \"0.4âˆ’1.0 mLÂ·minâˆ’1\".\n",
      "    - Total flow rate is mentioned for fuming nitric acid solution (\"0.8âˆ’2.2 mLÂ·minâˆ’1\"), but we need to infer the total based on\n",
      "Summarized 2/10:\n",
      "### Step-by-Step Solution ###\n",
      "\n",
      "## Step 1: Identify the reaction type\n",
      "The paragraph does not explicitly mention a specific chemical reaction or process it is referring to. Therefore, we will leave this field as null.\n",
      "\n",
      "## Step 2: Extract reactants and their roles\n",
      "There are no explicit mentions of reactant names in the provided text. Thus, we cannot accurately fill out the \"reactants\" section with any meaningful information beyond what's already stated (none).\n",
      "\n",
      "## Step 3: Identify products and optimal yield\n",
      "The paragraph does not explicitly mention a product or its yield directly related to the process being discussed. However, it mentions an organic compound becoming more evenly dispersed in the acid phase due to better mixing effects at faster flow rates.\n",
      "\n",
      "## Step 4: Extract conditions for the reaction\n",
      "- Temperature is mentioned as relevant but no specific value is given.\n",
      "- Residence time is also mentioned and implied to be affected by a faster flow rate.\n",
      "- Flow rate of reactant A (or total) isn't explicitly stated, so we'll leave this field empty since it's not directly provided in the text.\n",
      "\n",
      "## Step 5: Determine reactor type and inner diameter\n",
      "The paragraph mentions \"microchannel\" as part of the nitration process but does not specify a particular reactor type or its dimensions. However, given that microchannels are often associated with specific types of reactors (like microreactors), we might infer some details about the setup.\n",
      "\n",
      "## Step 6: Calculate metrics\n",
      "Summarized 3/10:\n",
      "### Step-by-Step Solution ###\n",
      "To solve this task, we will follow these steps:\n",
      "\n",
      "1. Identify the reaction type.\n",
      "2. Extract reactants and their roles (reactant/catalyst/solvent).\n",
      "3. Determine products with optimal yield percentage.\n",
      "4. Gather conditions: temperature in Â°C, residence time in min, flow rate of each reagent in mL/min, total flow rate in mL/min, pressure is not mentioned so we will use null for it.\n",
      "5. Identify the reactor type and inner diameter.\n",
      "\n",
      "### Step 1: Reaction Type\n",
      "The reaction type is not explicitly stated; therefore, we set \"reaction_type\" to null.\n",
      "\n",
      "```json\n",
      "\"reaction_summary\": {\n",
      "    \"reaction_type\": null,\n",
      "```\n",
      "\n",
      "### Step 2: Reactants\n",
      "We have two reactant solutions but no indication of their chemical names. We will assume they are the focus of the reaction and thus mark them as reactants without specifying roles since we cannot infer from given text.\n",
      "\n",
      "```json\n",
      "\"reactants\":[{\n",
      "    \"name\": null,\n",
      "```\n",
      "\n",
      "### Step 3: Products\n",
      "There is mention of a mixed solution being introduced into the microreactor, but no specific products are mentioned. We will assume there might be some form of product or outcome and set yield to optimal at 95% as it's the closest information we have regarding outcomes.\n",
      "\n",
      "```json\n",
      "\"products\":[{\n",
      "    \"name\": null,\n",
      "    \"yield_optimal\": 95,\n",
      "```\n",
      "Summarized 4/10:\n",
      "{\"name\":\"TFM\",\"role\":\"reactant\"}\n",
      "Summarized 5/10:\n",
      "### Input Text ###\n",
      "Process Development and Scale-up of the Continuous Flow Nitration of Triï¬‚uoromethoxybenzene Zhenghui Wen,â€ ,â€¡ Fengjun Jiao,â€  Mei Yang,â€  Shuainan Zhao,â€ ,â€¡ Feng Zhou,â€ ,â€¡ and Guangwen Chen*,â€  â€ Dalian National Laboratory for Clean Energy, Dalian Institute of Chemical Physics, Chinese Academy of Sciences, Dalian 116023, China â€¡University of Chinese Academy of Sciences, Beijing 100049, China * S Supporti\n",
      "\n",
      "### Step 1: Identify the reaction type\n",
      "The text does not explicitly mention the reaction type.\n",
      "\n",
      "### Step 2: Extract reactants and their roles\n",
      "There are no explicit mentions of reactants in the provided paragraph. Therefore, we will leave this field as null for now.\n",
      "\n",
      "### Step 3: Determine products and optimal yield\n",
      "The product is Triï¬‚uoromethoxybenzene but it's being nitrated so let's call it \"Triï¬‚uoromethoxybenzonitrate\". The text does not explicitly mention the optimal yield, but we can infer that since there are no other products mentioned and this seems to be a process development paper for nitration of Triï¬‚uoromethoxybenzene, then 95% is likely correct.\n",
      "\n",
      "### Step 4: Extract conditions\n",
      "The paragraph mentions \"Continuous Flow Nitration\" which implies the use of\n",
      "Summarized 6/10:\n",
      "{\"name\": \"null\", \"role\": \"null\"}\n",
      "Summarized 7/10:\n",
      "{\n",
      "    \"name\":\"TFMB\",\n",
      "    \"role\":null\n",
      "}],\n",
      "\"products\":[{\n",
      "    \"name\": null,\n",
      "    \"yield_optimal\": 99.6, # Assuming yield optimal is the same as conversion rate given in paragraph.\n",
      "    \"unit\": \"%\"\n",
      "}\n",
      "Summarized 8/10:\n",
      "{\"name\": \"m-NB\", \"role\": \"reactant\"},\n",
      "    {\"name\": \"DNB\", \"role\": \"reactant\"}\n",
      "]\n",
      "products = [{\"name\": null, \"yield_optimal\": 95, \"unit\": \"%\"}\n",
      "Summarized 9/10:\n",
      "### Step-by-Step Solution ###\n",
      "\n",
      "## Step 1: Identify the reaction type\n",
      "The paragraph does not explicitly mention the reaction type.\n",
      "\n",
      "## Step 2: Extract reactants and their roles\n",
      "There is no information about specific reactants in this text. However, TFMB (presumably a chemical compound) is mentioned as part of an effect study on flow rate but its role isn't specified beyond being affected by conditions.\n",
      "\n",
      "## Step 3: Identify products with optimal yield\n",
      "The paragraph mentions the product selectivity for TFMB conversion but does not explicitly state any other products. However, it implies that there are multiple products since \"product\" is mentioned in plural form (\"products\").\n",
      "\n",
      "## Step 4: Extract reaction conditions\n",
      "- Temperature (T) = 273 K.\n",
      "- Flow rate information isn't directly provided; however, the effect of flow rate on conversion and selectivity suggests its importance but doesnâ€™t give a specific value.\n",
      "\n",
      "## Step 5: Determine reactor type and inner diameter\n",
      "The microreactor is cooled by running water. The text does not explicitly mention the inner diameter or provide enough detail to infer it accurately without additional context that isn't provided.\n",
      "\n",
      "## Step 6: Extract metrics (conversion, yield, selectivity)\n",
      "- Conversion of TFMB = Not directly stated but implied in Figure 7.\n",
      "- Selectivity is mentioned as affected by flow rate but no specific value is given for any product.\n",
      "- Yield information isnâ€™t explicitly available; however, the mention\n",
      "Summarized 10/10:\n",
      "{\"name\": null,\"role\":\"null\"}],\n",
      "\"products\":[{\"name\": \"p-Nitrobenzene\",\"yield_optimal\": 91.08, \"unit\": \"%\"}, {\"name\": \"o-Nitrobenzene\", \"yield_optimal\": 7.05, \"unit\": \"%\"}\n",
      "  âœ… æ€»ç»“å®Œæˆ: Embedding_101021acsoprd7b00291_Filtered_Abstract_Summarized.txt\n",
      "\n",
      "ğŸ‰ æŠ½è±¡å’Œæ€»ç»“å®Œæˆï¼\n"
     ]
    }
   ],
   "source": [
    "import os # ç¡®ä¿ os æ¨¡å—å·²å¯¼å…¥\n",
    "\n",
    "print(\"ğŸš€ æ­¥éª¤ 5/5: æŠ½è±¡å’Œæ€»ç»“...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "abstract_files = []\n",
    "summarized_files = []\n",
    "\n",
    "# ä½¿ç”¨è¿‡æ»¤åçš„æ–‡ä»¶è¿›è¡ŒæŠ½è±¡å’Œæ€»ç»“\n",
    "for i, filter_file in enumerate(filter_files, 1):\n",
    "    print(f\"\\nğŸ“„ å¤„ç†æ–‡ä»¶ {i}/{len(filter_files)}: {os.path.basename(filter_file)}\")\n",
    "    \n",
    "\n",
    "    # --- æŠ½è±¡ (Abstract) æ­¥éª¤ ---\n",
    "    # 1. é¦–å…ˆï¼Œæ ¹æ®è¾“å…¥æ–‡ä»¶åï¼Œæ¨æ–­å‡ºè¾“å‡ºæ–‡ä»¶çš„åº”æœ‰è·¯å¾„\n",
    "    #    ä¾‹å¦‚ï¼Œå°† '..._Filtered.txt' æ›¿æ¢ä¸º '..._Abstract.txt'\n",
    "    abstract_file_path = filter_file.replace('_Filtered.txt', '_Abstract.txt')\n",
    "\n",
    "    # 2. æ£€æŸ¥è¿™ä¸ªè¾“å‡ºæ–‡ä»¶æ˜¯å¦å·²ç»å­˜åœ¨\n",
    "    if os.path.exists(abstract_file_path):\n",
    "        # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œåˆ™è·³è¿‡å¤„ç†\n",
    "        print(f\"  â­ï¸  æ£€æµ‹åˆ°å·²å­˜åœ¨æ–‡ä»¶ï¼Œè·³è¿‡ [æŠ½è±¡] æ­¥éª¤: {os.path.basename(abstract_file_path)}\")\n",
    "    else:\n",
    "        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ‰æ‰§è¡Œè€—æ—¶çš„LLMè°ƒç”¨\n",
    "        print(\"  â³  æ­£åœ¨æ‰§è¡Œ [æŠ½è±¡]...\")\n",
    "        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬å‡è®¾ process_text_file_for_abstract è¿”å›çš„æ˜¯å®ƒåˆ›å»ºçš„æ–‡ä»¶è·¯å¾„\n",
    "        abstract_file_path = process_text_file_for_abstract(filter_file)\n",
    "        print(f\"  âœ… æŠ½è±¡å®Œæˆ: {os.path.basename(abstract_file_path)}\")\n",
    "    \n",
    "    # æ— è®ºæ˜¯å¦è·³è¿‡ï¼Œéƒ½å°†è·¯å¾„æ·»åŠ åˆ°åˆ—è¡¨ä¸­\n",
    "    abstract_files.append(abstract_file_path)\n",
    "\n",
    "    # --- æ€»ç»“ (Summarize) æ­¥éª¤ ---\n",
    "    # 1. åŒæ ·ï¼Œå…ˆæ¨æ–­å‡ºè¾“å‡ºæ–‡ä»¶çš„è·¯å¾„\n",
    "    summarized_file_path = filter_file.replace('_Filtered.txt', '_Summarized.txt')\n",
    "\n",
    "    # 2. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨\n",
    "    if os.path.exists(summarized_file_path):\n",
    "        # å¦‚æœå·²å­˜åœ¨ï¼Œåˆ™è·³è¿‡\n",
    "        print(f\"  â­ï¸  æ£€æµ‹åˆ°å·²å­˜åœ¨æ–‡ä»¶ï¼Œè·³è¿‡ [æ€»ç»“] æ­¥éª¤: {os.path.basename(summarized_file_path)}\")\n",
    "    else:\n",
    "        # å¦‚æœä¸å­˜åœ¨ï¼Œæ‰æ‰§è¡Œ\n",
    "        # é‡è¦æç¤ºï¼šæ ¹æ®æˆ‘ä»¬ä¹‹å‰çš„è®¨è®ºï¼Œæ€»ç»“æ­¥éª¤çš„æœ€ä½³è¾“å…¥æ˜¯â€œæŠ½è±¡â€åçš„æ–‡æœ¬ï¼Œè€Œä¸æ˜¯â€œè¿‡æ»¤â€åçš„æ–‡æœ¬ã€‚\n",
    "        # å› æ­¤ï¼Œè¿™é‡Œä¼ é€’ abstract_file_path ä½œä¸ºè¾“å…¥ä¼šæ›´é«˜æ•ˆå’Œå‡†ç¡®ã€‚\n",
    "        print(\"  â³  æ­£åœ¨æ‰§è¡Œ [æ€»ç»“]...\")\n",
    "        summarized_file_path = process_text_file_for_summerized(abstract_file_path)\n",
    "        print(f\"  âœ… æ€»ç»“å®Œæˆ: {os.path.basename(summarized_file_path)}\")\n",
    "\n",
    "    # æ— è®ºæ˜¯å¦è·³è¿‡ï¼Œéƒ½å°†è·¯å¾„æ·»åŠ åˆ°åˆ—è¡¨ä¸­\n",
    "    summarized_files.append(summarized_file_path)\n",
    "\n",
    "\n",
    "print(f\"\\nğŸ‰ æŠ½è±¡å’Œæ€»ç»“å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44237bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“– æŸ¥çœ‹åµŒå…¥æ–‡ä»¶: Embedding_101021acsoprd7b00291.txt\n",
      "==================================================\n",
      "ğŸ“Š åµŒå…¥ç›¸ä¼¼åº¦ç­›é€‰åæ®µè½æ•°: 20\n",
      "\n",
      "ğŸ“„ ç›¸ä¼¼åº¦æœ€é«˜çš„æ®µè½é¢„è§ˆ:\n",
      "------------------------------\n",
      "æ®µè½ 1: The general laboratory process developments were carried out in microchannel reactors. TFMB (7.57 M, ï¬‚ow rate of 0.4âˆ’1.0 mLÂ·minâˆ’1) and a solution of fuming nitric acid in concentrated sulfuric acid (2...\n",
      "æ®µè½ 3: A faster ï¬‚ow rate would result in a better mixing eï¬€ect, which can make the organic compound more evenly dispersed in the acid phase. Besides, a faster ï¬‚ow rate would also decrease the residence time....\n"
     ]
    }
   ],
   "source": [
    "# æŸ¥çœ‹åµŒå…¥ç»“æœ\n",
    "sample_embedding = embedding_files[0]\n",
    "print(f\"ğŸ“– æŸ¥çœ‹åµŒå…¥æ–‡ä»¶: {os.path.basename(sample_embedding)}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "with open(sample_embedding, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "print(f\"ğŸ“Š åµŒå…¥ç›¸ä¼¼åº¦ç­›é€‰åæ®µè½æ•°: {len(lines)}\")\n",
    "print(\"\\nğŸ“„ ç›¸ä¼¼åº¦æœ€é«˜çš„æ®µè½é¢„è§ˆ:\")\n",
    "print(\"-\" * 30)\n",
    "for i, line in enumerate(lines[:3]):\n",
    "    if line.strip():\n",
    "        print(f\"æ®µè½ {i+1}: {line[:200]}...\" if len(line) > 200 else f\"æ®µè½ {i+1}: {line}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dceb377e",
   "metadata": {},
   "source": [
    "### ğŸ” æŸ¥çœ‹æœ€ç»ˆç»“æœ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38340a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“– æŸ¥çœ‹æœ€ç»ˆæ€»ç»“: Embedding_101021acsoprd7b00291_Filtered_Abstract_Summarized.txt\n",
      "==================================================\n",
      "ğŸ“Š æ€»ç»“å†…å®¹é•¿åº¦: 7311 å­—ç¬¦\n",
      "\n",
      "ğŸ“„ æ€»ç»“å†…å®¹é¢„è§ˆ:\n",
      "------------------------------\n",
      "### Step-by-Step Solution ###\n",
      "\n",
      "## Step 1: Identify the reaction type\n",
      "The paragraph does not explicitly mention a specific chemical reaction or process beyond mentioning it as part of general laboratory process developments. Therefore, we will leave this field blank.\n",
      "\n",
      "## Step 2: Extract reactants and their roles\n",
      "From the text, two substances are mentioned:\n",
      "- TFMB (7.57 M) delivered by one syringe pump.\n",
      "- A solution of fuming nitric acid in concentrated sulfuric acid (2.49âˆ’3.19 M), also delivered by a separate syringe pump.\n",
      "\n",
      "Given that both are involved in reacting within capillaries, we can infer they act as reactants but cannot determine their roles without further context or information on the reaction type.\n",
      "\n",
      "## Step 3: Extract products and yields\n",
      "There is no mention of specific chemical products formed from this process. Therefore, we will leave these fields blank for now.\n",
      "\n",
      "## Step 4: Determine conditions\n",
      "- Temperature: Not explicitly mentioned.\n",
      "- Residence Time: The length of capill...\n"
     ]
    }
   ],
   "source": [
    "# æŸ¥çœ‹æœ€ç»ˆæ€»ç»“ç»“æœ\n",
    "sample_summarized = summarized_files[0]\n",
    "print(f\"ğŸ“– æŸ¥çœ‹æœ€ç»ˆæ€»ç»“: {os.path.basename(sample_summarized)}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "with open(sample_summarized, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "    content = f.read()\n",
    "    \n",
    "print(f\"ğŸ“Š æ€»ç»“å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦\")\n",
    "print(\"\\nğŸ“„ æ€»ç»“å†…å®¹é¢„è§ˆ:\")\n",
    "print(\"-\" * 30)\n",
    "print(content[:1000] + \"...\" if len(content) > 1000 else content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47901c5c",
   "metadata": {},
   "source": [
    "## ğŸ“Š å¤„ç†ç»“æœç»Ÿè®¡\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a0cd50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š OSSExtractor å¤„ç†ç»“æœç»Ÿè®¡\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>æ–‡ä»¶</th>\n",
       "      <th>åŸå§‹PDF (MB)</th>\n",
       "      <th>é¢„å¤„ç† (KB)</th>\n",
       "      <th>åµŒå…¥ç­›é€‰ (KB)</th>\n",
       "      <th>LLMè¿‡æ»¤ (KB)</th>\n",
       "      <th>æœ€ç»ˆæ€»ç»“ (KB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101021acsoprd7b00291.txt</td>\n",
       "      <td>0.03</td>\n",
       "      <td>26.96</td>\n",
       "      <td>8.26</td>\n",
       "      <td>8.26</td>\n",
       "      <td>7.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         æ–‡ä»¶  åŸå§‹PDF (MB)  é¢„å¤„ç† (KB)  åµŒå…¥ç­›é€‰ (KB)  LLMè¿‡æ»¤ (KB)  \\\n",
       "0  101021acsoprd7b00291.txt        0.03     26.96       8.26        8.26   \n",
       "\n",
       "   æœ€ç»ˆæ€»ç»“ (KB)  \n",
       "0       7.19  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ‰ æ‰€æœ‰å¤„ç†æ­¥éª¤å®Œæˆï¼\n"
     ]
    }
   ],
   "source": [
    "# ç»Ÿè®¡å¤„ç†ç»“æœ\n",
    "print(\"ğŸ“Š OSSExtractor å¤„ç†ç»“æœç»Ÿè®¡\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "stats = []\n",
    "for i, file_path in enumerate(output_files):\n",
    "    filename = os.path.basename(file_path)\n",
    "    \n",
    "    # ç»Ÿè®¡å„ä¸ªæ­¥éª¤çš„æ–‡ä»¶å¤§å°\n",
    "    original_size = os.path.getsize(file_path) if os.path.exists(file_path) else 0\n",
    "    \n",
    "    processed_file = processed_files[i] if i < len(processed_files) else None\n",
    "    processed_size = os.path.getsize(processed_file) if processed_file and os.path.exists(processed_file) else 0\n",
    "    \n",
    "    embedding_file = embedding_files[i] if i < len(embedding_files) else None\n",
    "    embedding_size = os.path.getsize(embedding_file) if embedding_file and os.path.exists(embedding_file) else 0\n",
    "    \n",
    "    filter_file = filter_files[i] if i < len(filter_files) else None\n",
    "    filter_size = os.path.getsize(filter_file) if filter_file and os.path.exists(filter_file) else 0\n",
    "    \n",
    "    summarized_file = summarized_files[i] if i < len(summarized_files) else None\n",
    "    summarized_size = os.path.getsize(summarized_file) if summarized_file and os.path.exists(summarized_file) else 0\n",
    "    \n",
    "    stats.append({\n",
    "        'æ–‡ä»¶': filename,\n",
    "        'åŸå§‹PDF (MB)': round(original_size / 1024 / 1024, 2),\n",
    "        'é¢„å¤„ç† (KB)': round(processed_size / 1024, 2),\n",
    "        'åµŒå…¥ç­›é€‰ (KB)': round(embedding_size / 1024, 2),\n",
    "        'LLMè¿‡æ»¤ (KB)': round(filter_size / 1024, 2),\n",
    "        'æœ€ç»ˆæ€»ç»“ (KB)': round(summarized_size / 1024, 2)\n",
    "    })\n",
    "\n",
    "# æ˜¾ç¤ºç»Ÿè®¡è¡¨æ ¼\n",
    "df_stats = pd.DataFrame(stats)\n",
    "display(df_stats)\n",
    "\n",
    "print(\"\\nğŸ‰ æ‰€æœ‰å¤„ç†æ­¥éª¤å®Œæˆï¼\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147de13a",
   "metadata": {},
   "source": [
    "## ğŸ”§ è°ƒè¯•å’Œä¼˜åŒ–å»ºè®®\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d08b082",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ”§ è°ƒè¯•å’Œä¼˜åŒ–å»ºè®®\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\"\"\n",
    "1. ğŸ“Š æ£€æŸ¥åµŒå…¥ç›¸ä¼¼åº¦é˜ˆå€¼\n",
    "   - å¦‚æœç­›é€‰çš„æ®µè½å¤ªå°‘ï¼Œå¯ä»¥é™ä½ç›¸ä¼¼åº¦é˜ˆå€¼\n",
    "   - å¦‚æœç­›é€‰çš„æ®µè½å¤ªå¤šï¼Œå¯ä»¥æé«˜ç›¸ä¼¼åº¦é˜ˆå€¼\n",
    "\n",
    "2. ğŸ¤– ä¼˜åŒ–LLMæç¤ºè¯\n",
    "   - åœ¨Filter.pyä¸­è°ƒæ•´é—®é¢˜æè¿°\n",
    "   - åœ¨Summerized.pyä¸­è°ƒæ•´å‚æ•°æå–æç¤ºè¯\n",
    "\n",
    "3. ğŸ“ è°ƒæ•´æ–‡æœ¬é¢„å¤„ç†\n",
    "   - åœ¨TXT_Processing.pyä¸­ä¿®æ”¹è¿‡æ»¤è§„åˆ™\n",
    "   - è°ƒæ•´æ®µè½åˆ†å‰²ç­–ç•¥\n",
    "\n",
    "4. ğŸ” æ£€æŸ¥æ¨¡å‹æ€§èƒ½\n",
    "   - è§‚å¯ŸLLMçš„å“åº”è´¨é‡\n",
    "   - è€ƒè™‘è°ƒæ•´æ¨¡å‹å‚æ•°ï¼ˆtemp, top_pç­‰ï¼‰\n",
    "\n",
    "5. ğŸ“ˆ å¯è§†åŒ–å¤„ç†æµç¨‹\n",
    "   - ç»˜åˆ¶å„æ­¥éª¤çš„æ•°æ®é‡å˜åŒ–\n",
    "   - åˆ†æå¤„ç†æ•ˆç‡\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3912b46",
   "metadata": {},
   "source": [
    "## ğŸ“Š ç»“æœæŸ¥çœ‹å’Œåˆ†æ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b00104c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š æŸ¥çœ‹å¤„ç†ç»“æœ...\n",
      "==================================================\n",
      "\n",
      "ğŸ“ åŸå§‹æ–‡æœ¬:\n",
      "  1. 101021acsoprd7b00291.txt (731 è¡Œ)\n",
      "\n",
      "ğŸ“ é¢„å¤„ç†æ–‡æœ¬:\n",
      "  1. Processed_101021acsoprd7b00291.txt (68 è¡Œ)\n",
      "\n",
      "ğŸ“ åµŒå…¥æ–‡ä»¶:\n",
      "  1. Embedding_101021acsoprd7b00291.txt (20 è¡Œ)\n",
      "\n",
      "ğŸ“ è¿‡æ»¤æ–‡ä»¶:\n",
      "  1. Embedding_101021acsoprd7b00291_Filtered.txt (20 è¡Œ)\n",
      "\n",
      "ğŸ“ æŠ½è±¡æ–‡ä»¶:\n",
      "  1. Embedding_101021acsoprd7b00291_Filtered_Abstract.txt (20 è¡Œ)\n",
      "\n",
      "ğŸ“ æ€»ç»“æ–‡ä»¶:\n",
      "  1. Embedding_101021acsoprd7b00291_Filtered_Abstract_Summarized.txt (137 è¡Œ)\n",
      "\n",
      "ğŸ‰ å¤„ç†å®Œæˆï¼å…±å¤„ç†äº† 1 ä¸ªPDFæ–‡ä»¶\n"
     ]
    }
   ],
   "source": [
    "# æŸ¥çœ‹æœ€ç»ˆç»“æœ\n",
    "print(\"ğŸ“Š æŸ¥çœ‹å¤„ç†ç»“æœ...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# æ˜¾ç¤ºæ‰€æœ‰ç”Ÿæˆçš„æ–‡ä»¶\n",
    "all_files = {\n",
    "    'åŸå§‹æ–‡æœ¬': output_files,\n",
    "    'é¢„å¤„ç†æ–‡æœ¬': processed_files,\n",
    "    'åµŒå…¥æ–‡ä»¶': embedding_files,\n",
    "    'è¿‡æ»¤æ–‡ä»¶': filter_files,\n",
    "    'æŠ½è±¡æ–‡ä»¶': abstract_files,\n",
    "    'æ€»ç»“æ–‡ä»¶': summarized_files\n",
    "}\n",
    "\n",
    "for category, files in all_files.items():\n",
    "    print(f\"\\nğŸ“ {category}:\")\n",
    "    for i, file in enumerate(files, 1):\n",
    "        if os.path.exists(file):\n",
    "            with open(file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                lines = f.readlines()\n",
    "            print(f\"  {i}. {os.path.basename(file)} ({len(lines)} è¡Œ)\")\n",
    "        else:\n",
    "            print(f\"  {i}. {os.path.basename(file)} (æ–‡ä»¶ä¸å­˜åœ¨)\")\n",
    "\n",
    "print(f\"\\nğŸ‰ å¤„ç†å®Œæˆï¼å…±å¤„ç†äº† {len(pdf_files)} ä¸ªPDFæ–‡ä»¶\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b6f7ab",
   "metadata": {},
   "source": [
    "## ğŸ” ç»“æœåˆ†æ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65ff5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” åˆ†ææœ€ç»ˆç»“æœ...\n",
      "==================================================\n",
      "ğŸ“„ æœ€ç»ˆæ€»ç»“ç»“æœ:\n",
      "\n",
      "æ–‡ä»¶ 1: Embedding_101021acsoprd7b00291_Filtered_Abstract_Summarized.txt\n",
      "å†…å®¹é¢„è§ˆ:\n",
      "------------------------------\n",
      "### Step-by-Step Solution ###\n",
      "\n",
      "## Step 1: Identify the reaction type\n",
      "The paragraph does not explicitly mention a specific chemical reaction or process beyond mentioning it as part of general laboratory process developments. Therefore, we will leave this field blank.\n",
      "\n",
      "## Step 2: Extract reactants and their roles\n",
      "From the text, two substances are mentioned:\n",
      "- TFMB (7.57 M) delivered by one syringe pump.\n",
      "- A solution of fuming nitric acid in concentrated sulfuric acid (2.49âˆ’3.19 M), also delivered ...\n"
     ]
    }
   ],
   "source": [
    "# åˆ†ææœ€ç»ˆç»“æœ\n",
    "print(\"ğŸ” åˆ†ææœ€ç»ˆç»“æœ...\")\n",
    "print(\"=\" * 50)\n",
    "# æŸ¥çœ‹æ€»ç»“æ–‡ä»¶çš„å†…å®¹\n",
    "if summarized_files:\n",
    "    print(\"ğŸ“„ æœ€ç»ˆæ€»ç»“ç»“æœ:\")\n",
    "    for i, file in enumerate(summarized_files, 1):\n",
    "        print(f\"\\næ–‡ä»¶ {i}: {os.path.basename(file)}\")\n",
    "        if os.path.exists(file):\n",
    "            with open(file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                content = f.read()\n",
    "            print(\"å†…å®¹é¢„è§ˆ:\")\n",
    "            print(\"-\" * 30)\n",
    "            print(content[:500] + \"...\" if len(content) > 500 else content)\n",
    "        else:\n",
    "            print(\"æ–‡ä»¶ä¸å­˜åœ¨\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712c2321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ˜¾ç¤ºå¤„ç†ç»Ÿè®¡ä¿¡æ¯\n",
    "print(\"\\nğŸ“Š å¤„ç†ç»Ÿè®¡ä¿¡æ¯:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "total_paragraphs_original = 0\n",
    "total_paragraphs_filtered = 0\n",
    "\n",
    "for i, (original, filtered) in enumerate(zip(processed_files, filter_files), 1):\n",
    "    if os.path.exists(original):\n",
    "        with open(original, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            original_lines = len(f.readlines())\n",
    "        total_paragraphs_original += original_lines\n",
    "    \n",
    "    if os.path.exists(filtered):\n",
    "        with open(filtered, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            filtered_lines = len(f.readlines())\n",
    "        total_paragraphs_filtered += filtered_lines\n",
    "        \n",
    "        print(f\"æ–‡ä»¶ {i}: {original_lines} â†’ {filtered_lines} æ®µè½ (ä¿ç•™ç‡: {filtered_lines/original_lines*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\næ€»è®¡: {total_paragraphs_original} â†’ {total_paragraphs_filtered} æ®µè½\")\n",
    "print(f\"æ•´ä½“ä¿ç•™ç‡: {total_paragraphs_filtered/total_paragraphs_original*100:.1f}%\")\n",
    "\n",
    "print(f\"\\nğŸ‰ æ‘˜è¦ç»“è®ºä¸“ç”¨å¤„ç†å®Œæˆï¼\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ossextractor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
