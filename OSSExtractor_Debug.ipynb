{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30dcbcd6",
   "metadata": {},
   "source": [
    "# ğŸ”¬ OSSExtractor è¡¨é¢åˆæˆå‚æ•°æå–å·¥å…· - è°ƒè¯•ç‰ˆæœ¬\n",
    "\n",
    "æœ¬notebookå…è®¸æ‚¨é€æ­¥è°ƒè¯•OSSExtractorçš„æ¯ä¸ªå¤„ç†æ­¥éª¤ï¼ŒæŸ¥çœ‹ä¸­é—´ç»“æœå¹¶ä¼˜åŒ–å‚æ•°ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29deb780",
   "metadata": {},
   "source": [
    "## ğŸ“¦ å¯¼å…¥å¿…è¦çš„åº“å’Œæ¨¡å—\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4e064e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ‰€æœ‰æ¨¡å—å¯¼å…¥æˆåŠŸï¼\n",
      "ğŸ”„ ç»Ÿä¸€å¤„ç†æ¨¡å—:\n",
      "  - PDF_Unified_Processor: ç»Ÿä¸€PDFå¤„ç† (PyMuPDF)\n",
      "  - Unified_Text_Processor: ç»Ÿä¸€æ–‡æœ¬å¤„ç† (LLM)\n",
      "  - å…¼å®¹åŸæœ‰æ¥å£ï¼ŒåŠŸèƒ½æ›´å¼ºå¤§\n",
      "  - æ”¯æŒåŸºç¡€æ–‡æœ¬æå–å’Œç»“æ„åŒ–è§£æ\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# æ·»åŠ æ¨¡å—è·¯å¾„\n",
    "sys.path.append('Text Parser')\n",
    "sys.path.append('Text Extraction')\n",
    "\n",
    "# å¯¼å…¥ç»Ÿä¸€çš„å¤„ç†æ¨¡å—\n",
    "from PDF_Unified_Processor import PDFUnifiedProcessor, save_contents_to_specific_folders\n",
    "from TXT_Processing import process_text_file_for_processing\n",
    "from Embedding_and_Similarity import process_text_file_for_embedding\n",
    "from Unified_Text_Processor import (\n",
    "    process_text_file_for_filter, process_text_file_for_abstract, process_text_file_for_summerized,\n",
    "    process_text_file_for_filter_meta_llama, process_text_file_for_abstract_meta_llama, \n",
    "    process_text_file_for_summerized_meta_llama\n",
    ")\n",
    "\n",
    "print(\"âœ… æ‰€æœ‰æ¨¡å—å¯¼å…¥æˆåŠŸï¼\")\n",
    "print(\"ğŸ”„ ç»Ÿä¸€å¤„ç†æ¨¡å—:\")\n",
    "print(\"  - PDF_Unified_Processor: ç»Ÿä¸€PDFå¤„ç† (PyMuPDF)\")\n",
    "print(\"  - Unified_Text_Processor: ç»Ÿä¸€æ–‡æœ¬å¤„ç† (LLM)\")\n",
    "print(\"  - å…¼å®¹åŸæœ‰æ¥å£ï¼ŒåŠŸèƒ½æ›´å¼ºå¤§\")\n",
    "print(\"  - æ”¯æŒåŸºç¡€æ–‡æœ¬æå–å’Œç»“æ„åŒ–è§£æ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195375cc",
   "metadata": {},
   "source": [
    "## ğŸ”„ å¤„ç†æµç¨‹è¯´æ˜\n",
    "\n",
    "**OSSExtractorçš„å®Œæ•´å¤„ç†æµç¨‹ï¼š**\n",
    "\n",
    "1. **PDFè½¬æ–‡æœ¬** â†’ åŸå§‹æ–‡æœ¬æ–‡ä»¶\n",
    "2. **æ–‡æœ¬é¢„å¤„ç†** â†’ æ®µè½åˆ†å‰²å’Œè¿‡æ»¤\n",
    "3. **åµŒå…¥ç›¸ä¼¼åº¦ç­›é€‰** â†’ ä»æ‰€æœ‰æ®µè½ä¸­é€‰å‡ºæœ€ç›¸å…³çš„Nä¸ªæ®µè½\n",
    "4. **LLMå†…å®¹è¿‡æ»¤** â†’ ä»ç›¸ä¼¼åº¦ç­›é€‰çš„æ®µè½ä¸­è¿›ä¸€æ­¥ç­›é€‰\n",
    "5. **æŠ½è±¡å’Œæ€»ç»“** â†’ ç”Ÿæˆæœ€ç»ˆçš„ç»“æ„åŒ–å‚æ•°\n",
    "\n",
    "**æ®µè½æ•°é‡å˜åŒ–ç¤ºä¾‹ï¼š**\n",
    "- åŸå§‹æ–‡æœ¬: 100+ æ®µè½\n",
    "- é¢„å¤„ç†å: 50+ æ®µè½  \n",
    "- åµŒå…¥ç­›é€‰å: 20 æ®µè½ (æœ€ç›¸å…³çš„)\n",
    "- LLMè¿‡æ»¤å: 10 æ®µè½ (æœ€ç¬¦åˆè¦æ±‚çš„)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87aff02e",
   "metadata": {},
   "source": [
    "## ğŸ”§ é…ç½®å‚æ•°\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a93a1594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“„ å°†å¤„ç† 1 ä¸ªPDFæ–‡ä»¶:\n",
      "ğŸ“ ä¸»è¾“å‡ºç›®å½•å·²è®¾ç½®ä¸º: /Users/zhaowenyuan/Projects/FCPDExtractor/Data/output\n",
      "----------------------------------------\n",
      "  1. æ­£åœ¨å¤„ç†: on-surface-synthesis-of.pdf\n",
      "     -> å°†è¾“å‡ºåˆ°: /Users/zhaowenyuan/Projects/FCPDExtractor/Data/output/on-surface-synthesis-of\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# é…ç½®è¦å¤„ç†çš„PDFæ–‡ä»¶\n",
    "pdf_files = [\n",
    "    '/Users/zhaowenyuan/Projects/FCPDExtractor/Data/papers/on-surface-synthesis-of.pdf',\n",
    "    # å¦‚æœæœ‰æ›´å¤šæ–‡ä»¶ï¼Œå¯ä»¥åŠ åœ¨è¿™é‡Œ\n",
    "    # '/Users/zhaowenyuan/Projects/FCPDExtractor/Data/papers/another_paper.pdf',\n",
    "]\n",
    "\n",
    "# å®šä¹‰åŸºç¡€çš„æ•°æ®ç›®å½•\n",
    "base_data_dir = '/Users/zhaowenyuan/Projects/FCPDExtractor/Data'\n",
    "\n",
    "# 1. åœ¨Dataç›®å½•ä¸‹ï¼Œå®šä¹‰ä¸€ä¸ªåä¸º 'output' çš„ä¸»è¾“å‡ºæ–‡ä»¶å¤¹è·¯å¾„\n",
    "main_output_dir = os.path.join(base_data_dir, 'output')\n",
    "\n",
    "# 2. åˆ›å»º 'output' æ–‡ä»¶å¤¹ (å¦‚æœå®ƒä¸å­˜åœ¨çš„è¯)\n",
    "# exist_ok=True è¡¨ç¤ºå¦‚æœæ–‡ä»¶å¤¹å·²å­˜åœ¨ï¼Œåˆ™ä¸ä¼šæŠ¥é”™\n",
    "os.makedirs(main_output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"ğŸ“„ å°†å¤„ç† {len(pdf_files)} ä¸ªPDFæ–‡ä»¶:\")\n",
    "print(f\"ğŸ“ ä¸»è¾“å‡ºç›®å½•å·²è®¾ç½®ä¸º: {main_output_dir}\")\n",
    "print(\"-\" * 40) # æ‰“å°åˆ†å‰²çº¿\n",
    "\n",
    "# éå†æ¯ä¸€ä¸ªè¦å¤„ç†çš„PDFæ–‡ä»¶\n",
    "for i, pdf_path in enumerate(pdf_files, 1):\n",
    "    \n",
    "    # 3. ä»å®Œæ•´è·¯å¾„ä¸­è·å–PDFçš„æ–‡ä»¶å (ä¾‹å¦‚: 'd2cp03073j.pdf')\n",
    "    pdf_filename = os.path.basename(pdf_path)\n",
    "    \n",
    "    # 4. å»æ‰.pdfæ‰©å±•åï¼Œåˆ›å»ºæ–‡ä»¶å¤¹å (ä¾‹å¦‚: 'd2cp03073j')\n",
    "    folder_name = os.path.splitext(pdf_filename)[0]\n",
    "    \n",
    "    # 5. æ‹¼æ¥å‡ºè¿™ä¸ªPDFä¸“å±çš„è¾“å‡ºæ–‡ä»¶å¤¹çš„å®Œæ•´è·¯å¾„\n",
    "    specific_output_dir = os.path.join(main_output_dir, folder_name)\n",
    "    \n",
    "    # 6. åˆ›å»ºè¿™ä¸ªä¸“å±çš„æ–‡ä»¶å¤¹\n",
    "    os.makedirs(specific_output_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"  {i}. æ­£åœ¨å¤„ç†: {pdf_filename}\")\n",
    "    print(f\"     -> å°†è¾“å‡ºåˆ°: {specific_output_dir}\")\n",
    "\n",
    "    # --- åœ¨è¿™é‡Œæ¥ä¸Šä½ åç»­çš„å¤„ç†é€»è¾‘ ---\n",
    "    # ä¾‹å¦‚ï¼Œä½ ä¹‹åæ‰€æœ‰ä¿å­˜æ–‡ä»¶çš„æ“ä½œï¼Œéƒ½åº”è¯¥ä½¿ç”¨ `specific_output_dir` ä½œä¸ºè·¯å¾„\n",
    "    # processed_text_path = os.path.join(specific_output_dir, 'Processed_text.txt')\n",
    "    # with open(processed_text_path, 'w') as f:\n",
    "    #     f.write(\"è¿™é‡Œæ˜¯å¤„ç†åçš„æ–‡æœ¬\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4eb3a6",
   "metadata": {},
   "source": [
    "## ğŸ“„ æ­¥éª¤ 1: PDFè½¬æ–‡æœ¬å¤„ç†\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a110213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ æ­¥éª¤ 1/5: PDFè½¬æ–‡æœ¬å¤„ç†...\n",
      "==================================================\n",
      "âœ… PDFè½¬æ–‡æœ¬å®Œæˆï¼ç”Ÿæˆäº† 1 ä¸ªæ–‡æœ¬æ–‡ä»¶:\n",
      "  1. /Users/zhaowenyuan/Projects/FCPDExtractor/Data/output/on-surface-synthesis-of/on-surface-synthesis-of.txt\n",
      "     ğŸ“Š è¡Œæ•°: 533\n",
      "     ğŸ“ æ–‡ä»¶å¤§å°: 26193 bytes\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸš€ æ­¥éª¤ 1/5: PDFè½¬æ–‡æœ¬å¤„ç†...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# ä½¿ç”¨ç»Ÿä¸€çš„PDFå¤„ç†æ¨¡å—\n",
    "processor = PDFUnifiedProcessor()\n",
    "\n",
    "# æ‰§è¡ŒPDFè½¬æ–‡æœ¬\n",
    "output_files = save_contents_to_specific_folders(pdf_files, main_output_dir)\n",
    "\n",
    "print(f\"âœ… PDFè½¬æ–‡æœ¬å®Œæˆï¼ç”Ÿæˆäº† {len(output_files)} ä¸ªæ–‡æœ¬æ–‡ä»¶:\")\n",
    "for i, file in enumerate(output_files, 1):\n",
    "    print(f\"  {i}. {file}\")\n",
    "    \n",
    "    # æ˜¾ç¤ºæ–‡ä»¶å¤§å°å’Œè¡Œæ•°\n",
    "    if os.path.exists(file):\n",
    "        with open(file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            lines = f.readlines()\n",
    "            print(f\"     ğŸ“Š è¡Œæ•°: {len(lines)}\")\n",
    "            print(f\"     ğŸ“ æ–‡ä»¶å¤§å°: {os.path.getsize(file)} bytes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d163864",
   "metadata": {},
   "source": [
    "### ğŸ” æŸ¥çœ‹PDFè½¬æ–‡æœ¬ç»“æœ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "383ac1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“– æŸ¥çœ‹æ–‡ä»¶: on-surface-synthesis-of.txt\n",
      "==================================================\n",
      "ğŸ“Š æ€»å­—ç¬¦æ•°: 25875\n",
      "ğŸ“Š æ€»è¡Œæ•°: 533\n",
      "\n",
      "ğŸ“„ å‰500ä¸ªå­—ç¬¦é¢„è§ˆ:\n",
      "------------------------------\n",
      "On-Surface Synthesis of Oligo(indenoindene)\n",
      " Marco Di Giovannantonio,* Qiang Chen, JoseÌ I. Urgel, Pascal Ruï¬ƒeux, Carlo A. Pignedoli,\n",
      "Klaus MuÌˆllen,* Akimitsu Narita,* and Roman Fasel*\n",
      "Cite This: J. Am. Chem. Soc. 2020, 142, 12925âˆ’12929\n",
      "Read Online\n",
      "ACCESS\n",
      "Metrics & More\n",
      "Article Recommendations\n",
      "*\n",
      "sÄ±\n",
      "Supporting Information\n",
      "ABSTRACT: Fully conjugated ladder polymers (CLP) possess unique optical and electronic properties and are considered\n",
      "promising materials for applications in (opto)electronic dev...\n"
     ]
    }
   ],
   "source": [
    "# é€‰æ‹©ç¬¬ä¸€ä¸ªæ–‡ä»¶è¿›è¡Œè¯¦ç»†æŸ¥çœ‹\n",
    "sample_file = output_files[0]\n",
    "print(f\"ğŸ“– æŸ¥çœ‹æ–‡ä»¶: {os.path.basename(sample_file)}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "with open(sample_file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "    content = f.read()\n",
    "    \n",
    "print(f\"ğŸ“Š æ€»å­—ç¬¦æ•°: {len(content)}\")\n",
    "print(f\"ğŸ“Š æ€»è¡Œæ•°: {len(content.splitlines())}\")\n",
    "print(\"\\nğŸ“„ å‰500ä¸ªå­—ç¬¦é¢„è§ˆ:\")\n",
    "print(\"-\" * 30)\n",
    "print(content[:500] + \"...\" if len(content) > 500 else content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c90caea",
   "metadata": {},
   "source": [
    "### ğŸ” ç»“æ„åŒ–PDFè§£æï¼ˆå¯é€‰ï¼‰\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a2aae9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ç»“æ„åŒ–PDFè§£æï¼ˆé’ˆå¯¹æ‘˜è¦å’Œç»“è®ºï¼‰\n",
      "==================================================\n",
      "\n",
      "ğŸ“„ å¤„ç†æ–‡ä»¶ 1/1: on-surface-synthesis-of.pdf\n",
      "âœ… other ç« èŠ‚: 5 ä¸ªæ®µè½ -> /Users/zhaowenyuan/Projects/FCPDExtractor/Data/output/on-surface-synthesis-of/on-surface-synthesis-of_other.txt\n",
      "  âœ… other: 489 ä¸ªæ®µè½\n",
      "\n",
      "ğŸ‰ ç»“æ„åŒ–è§£æå®Œæˆï¼\n"
     ]
    }
   ],
   "source": [
    "# å¯é€‰ï¼šä½¿ç”¨ç»“æ„åŒ–è§£ææå–æ‘˜è¦å’Œç»“è®ºéƒ¨åˆ†\n",
    "print(\"ğŸ” ç»“æ„åŒ–PDFè§£æï¼ˆé’ˆå¯¹æ‘˜è¦å’Œç»“è®ºï¼‰\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "structured_results = []\n",
    "\n",
    "for i, pdf_path in enumerate(pdf_files, 1):\n",
    "    print(f\"\\nğŸ“„ å¤„ç†æ–‡ä»¶ {i}/{len(pdf_files)}: {os.path.basename(pdf_path)}\")\n",
    "    \n",
    "    # ä½¿ç”¨ç»Ÿä¸€å¤„ç†å™¨è¿›è¡Œç»“æ„åŒ–è§£æ\n",
    "    result = processor.process_pdf_comprehensive(pdf_path, main_output_dir, mode='structured')\n",
    "    structured_results.append(result)\n",
    "    \n",
    "    # æ˜¾ç¤ºç»“æœ\n",
    "    for section, file_path in result.items():\n",
    "        if os.path.exists(file_path):\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                lines = f.readlines()\n",
    "            print(f\"  âœ… {section}: {len(lines)} ä¸ªæ®µè½\")\n",
    "\n",
    "print(f\"\\nğŸ‰ ç»“æ„åŒ–è§£æå®Œæˆï¼\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8c6cf3",
   "metadata": {},
   "source": [
    "## ğŸ“ æ­¥éª¤ 2: æ–‡æœ¬é¢„å¤„ç†\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab72e5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ æ­¥éª¤ 2/5: æ–‡æœ¬é¢„å¤„ç†...\n",
      "==================================================\n",
      "\n",
      "ğŸ“„ å¤„ç†æ–‡ä»¶ 1/1: on-surface-synthesis-of.txt\n",
      "  âœ… é¢„å¤„ç†å®Œæˆï¼Œè¿‡æ»¤äº† 19 ä¸ªæ®µè½\n",
      "  ğŸ“ è¾“å‡ºæ–‡ä»¶: /Users/zhaowenyuan/Projects/FCPDExtractor/Data/output/on-surface-synthesis-of/Processed_on-surface-synthesis-of.txt\n",
      "\n",
      "ğŸ‰ æ–‡æœ¬é¢„å¤„ç†å®Œæˆï¼æ€»å…±è¿‡æ»¤äº† 19 ä¸ªæ®µè½\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸš€ æ­¥éª¤ 2/5: æ–‡æœ¬é¢„å¤„ç†...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "total_filtered_count = 0\n",
    "processed_files = []\n",
    "\n",
    "# å¤„ç†ä¸Šä¸€æ­¥ç”Ÿæˆçš„TXTæ–‡ä»¶ï¼Œè€Œä¸æ˜¯PDFæ–‡ä»¶\n",
    "for i, txt_file in enumerate(output_files, 1):\n",
    "    print(f\"\\nğŸ“„ å¤„ç†æ–‡ä»¶ {i}/{len(output_files)}: {os.path.basename(txt_file)}\")\n",
    "    \n",
    "    # æ‰§è¡Œæ–‡æœ¬é¢„å¤„ç† - å¤„ç†TXTæ–‡ä»¶\n",
    "    processed_file_path, filtered_count = process_text_file_for_processing(txt_file)\n",
    "    processed_files.append(processed_file_path)\n",
    "    total_filtered_count += filtered_count\n",
    "    \n",
    "    print(f\"  âœ… é¢„å¤„ç†å®Œæˆï¼Œè¿‡æ»¤äº† {filtered_count} ä¸ªæ®µè½\")\n",
    "    print(f\"  ğŸ“ è¾“å‡ºæ–‡ä»¶: {processed_file_path}\")\n",
    "\n",
    "print(f\"\\nğŸ‰ æ–‡æœ¬é¢„å¤„ç†å®Œæˆï¼æ€»å…±è¿‡æ»¤äº† {total_filtered_count} ä¸ªæ®µè½\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dab9779",
   "metadata": {},
   "source": [
    "### ğŸ” æŸ¥çœ‹é¢„å¤„ç†ç»“æœ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8664887d",
   "metadata": {},
   "source": [
    "### ğŸ’¡ LLMå†…å®¹è¿‡æ»¤è¯´æ˜\n",
    "\n",
    "**è¿™ä¸€æ­¥çš„ä½œç”¨ï¼š**\n",
    "- è¾“å…¥ï¼šåµŒå…¥ç›¸ä¼¼åº¦ç­›é€‰å‡ºçš„æ®µè½ï¼ˆå¦‚20ä¸ªæ®µè½ï¼‰\n",
    "- å¤„ç†ï¼šä½¿ç”¨Meta-Llama-3.1-8Bæ¨¡å‹åˆ¤æ–­æ¯ä¸ªæ®µè½æ˜¯å¦çœŸæ­£ä¸è¡¨é¢åŒ–å­¦ååº”ç›¸å…³\n",
    "- è¾“å‡ºï¼šè¿›ä¸€æ­¥ç­›é€‰çš„ç›¸å…³æ®µè½ï¼ˆå¦‚10ä¸ªæ®µè½ï¼‰\n",
    "\n",
    "**æ¨¡å‹é€‰æ‹©ï¼š**\n",
    "- ä¼˜å…ˆä½¿ç”¨ï¼šMeta-Llama-3.1-8B-Instructï¼ˆæ›´æ™ºèƒ½ï¼Œæ€§èƒ½æ›´å¥½ï¼‰\n",
    "- å›é€€æ¨¡å‹ï¼šnous-hermes-llama2-13bï¼ˆç¨³å®šå¯é ï¼‰\n",
    "\n",
    "**ä¸ºä»€ä¹ˆæ®µè½æ•°ä¼šå‡å°‘ï¼š**\n",
    "- åµŒå…¥ç›¸ä¼¼åº¦åªæ˜¯åŸºäºå…³é”®è¯åŒ¹é…\n",
    "- LLMè¿‡æ»¤ä¼šè¿›è¡Œæ›´æ™ºèƒ½çš„å†…å®¹ç†è§£\n",
    "- æœ€ç»ˆä¿ç•™çœŸæ­£ç›¸å…³çš„æ®µè½\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40a707c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” åˆ†ææ–‡ä»¶: on-surface-synthesis-of.txt\n",
      "==================================================\n",
      "ğŸ“Š åŸå§‹æ–‡ä»¶æ€»è¡Œæ•°: 533\n",
      "ğŸ“Š ç©ºè¡Œæ•°é‡: 34\n",
      "ğŸ“Š åˆ†å‰²åçš„æ®µè½æ•°: 34\n",
      "ğŸ“Š å¹³å‡æ®µè½é•¿åº¦: 757.6 å­—ç¬¦\n",
      "\n",
      "ğŸ“„ å‰5ä¸ªæ®µè½é¢„è§ˆ:\n",
      "------------------------------\n",
      "æ®µè½ 1 (é•¿åº¦: 936): On-Surface Synthesis of Oligo(indenoindene) Marco Di Giovannantonio,* Qiang Chen, JoseÌ I. Urgel, Pascal Ruï¬ƒeux, Carlo A. Pignedoli, Klaus MuÌˆllen,* A...\n",
      "æ®µè½ 2 (é•¿åº¦: 947): Achieving defect- free segments of oligo(indenoindene) oï¬€ers exclusive insight into this CLP and provides the basis to further synthetic approaches. C...\n",
      "æ®µè½ 3 (é•¿åº¦: 896): The synthesis of PInIns was pioneered by Scherf and MuÌˆllen in 1992, but the ï¬nal dehydrogenation step did not proceed completely, and unambiguous str...\n",
      "æ®µè½ 4 (é•¿åº¦: 943): Recently, we have established on-surface syntheses of indenoï¬‚uorene polymers by utilizing oxidative cyclization of methyl groups against phenylene rin...\n",
      "æ®µè½ 5 (é•¿åº¦: 371): Reaction Pathway from 1 to p-OInIn 4 on Au(111) Communication pubs.acs.org/JACS Â© 2020 American Chemical Society 12925 https://dx.doi.org/10.1021/jacs...\n",
      "\n",
      "ğŸ“Š æ€»ç»“:\n",
      "  - åŸå§‹æ–‡ä»¶è¡Œæ•°: 34\n",
      "  - é¢„å¤„ç†åæ®µè½æ•°: 25\n",
      "  - è¿‡æ»¤æ‰çš„æ®µè½æ•°: 9\n",
      "  - ä¿ç•™æ¯”ä¾‹: 73.5%\n"
     ]
    }
   ],
   "source": [
    "# è¯¦ç»†åˆ†ææ®µè½åˆ†å‰²è¿‡ç¨‹\n",
    "def analyze_paragraph_segmentation(txt_file):\n",
    "    print(f\"ğŸ” åˆ†ææ–‡ä»¶: {os.path.basename(txt_file)}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    with open(txt_file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    print(f\"ğŸ“Š åŸå§‹æ–‡ä»¶æ€»è¡Œæ•°: {len(lines)}\")\n",
    "    \n",
    "    # æ¨¡æ‹Ÿæ®µè½åˆ†å‰²è¿‡ç¨‹\n",
    "    current_segment = []\n",
    "    segments = []\n",
    "    empty_lines_count = 0\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        if line.strip():  # éç©ºè¡Œ\n",
    "            current_segment.append(line.strip())\n",
    "        else:  # ç©ºè¡Œ\n",
    "            empty_lines_count += 1\n",
    "            if current_segment:  # å¦‚æœå½“å‰æ®µè½ä¸ä¸ºç©º\n",
    "                segments.append(' '.join(current_segment))\n",
    "                current_segment = []\n",
    "    \n",
    "    # å¤„ç†æœ€åä¸€ä¸ªæ®µè½\n",
    "    if current_segment:\n",
    "        segments.append(' '.join(current_segment))\n",
    "    \n",
    "    print(f\"ğŸ“Š ç©ºè¡Œæ•°é‡: {empty_lines_count}\")\n",
    "    print(f\"ğŸ“Š åˆ†å‰²åçš„æ®µè½æ•°: {len(segments)}\")\n",
    "    print(f\"ğŸ“Š å¹³å‡æ®µè½é•¿åº¦: {sum(len(seg) for seg in segments) / len(segments):.1f} å­—ç¬¦\")\n",
    "    \n",
    "    print(\"\\nğŸ“„ å‰5ä¸ªæ®µè½é¢„è§ˆ:\")\n",
    "    print(\"-\" * 30)\n",
    "    for i, segment in enumerate(segments[:5]):\n",
    "        print(f\"æ®µè½ {i+1} (é•¿åº¦: {len(segment)}): {segment[:150]}...\" if len(segment) > 150 else f\"æ®µè½ {i+1} (é•¿åº¦: {len(segment)}): {segment}\")\n",
    "    \n",
    "    return segments\n",
    "\n",
    "# åˆ†æåŸå§‹TXTæ–‡ä»¶çš„æ®µè½åˆ†å‰²\n",
    "if output_files:\n",
    "    original_segments = analyze_paragraph_segmentation(output_files[0])\n",
    "    \n",
    "    print(f\"\\nğŸ“Š æ€»ç»“:\")\n",
    "    print(f\"  - åŸå§‹æ–‡ä»¶è¡Œæ•°: {len(original_segments)}\")\n",
    "    print(f\"  - é¢„å¤„ç†åæ®µè½æ•°: 25\")\n",
    "    print(f\"  - è¿‡æ»¤æ‰çš„æ®µè½æ•°: {len(original_segments) - 25}\")\n",
    "    print(f\"  - ä¿ç•™æ¯”ä¾‹: {25/len(original_segments)*100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6b4595",
   "metadata": {},
   "source": [
    "## ğŸ” æ­¥éª¤ 3: åµŒå…¥å’Œç›¸ä¼¼åº¦è®¡ç®—\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d1d9b5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ æ­¥éª¤ 3/5: åµŒå…¥å’Œç›¸ä¼¼åº¦è®¡ç®—...\n",
      "==================================================\n",
      "\n",
      "ğŸ“„ å¤„ç†æ–‡ä»¶ 1/1: Processed_on-surface-synthesis-of.txt\n",
      "  âœ… åµŒå…¥å’Œç›¸ä¼¼åº¦è®¡ç®—å®Œæˆ\n",
      "  ğŸ“ è¾“å‡ºæ–‡ä»¶: /Users/zhaowenyuan/Projects/FCPDExtractor/Data/output/on-surface-synthesis-of/Embedding_on-surface-synthesis-of.txt\n",
      "\n",
      "ğŸ‰ åµŒå…¥å’Œç›¸ä¼¼åº¦è®¡ç®—å®Œæˆï¼\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸš€ æ­¥éª¤ 3/5: åµŒå…¥å’Œç›¸ä¼¼åº¦è®¡ç®—...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "embedding_files = []\n",
    "\n",
    "# ä½¿ç”¨ä¸Šä¸€æ­¥é¢„å¤„ç†åçš„æ–‡ä»¶\n",
    "for i, processed_file in enumerate(processed_files, 1):\n",
    "    print(f\"\\nğŸ“„ å¤„ç†æ–‡ä»¶ {i}/{len(processed_files)}: {os.path.basename(processed_file)}\")\n",
    "    \n",
    "    # æ‰§è¡ŒåµŒå…¥å’Œç›¸ä¼¼åº¦è®¡ç®—\n",
    "    embedding_file_path = process_text_file_for_embedding(processed_file)\n",
    "    embedding_files.append(embedding_file_path)\n",
    "    \n",
    "    print(f\"  âœ… åµŒå…¥å’Œç›¸ä¼¼åº¦è®¡ç®—å®Œæˆ\")\n",
    "    print(f\"  ğŸ“ è¾“å‡ºæ–‡ä»¶: {embedding_file_path}\")\n",
    "\n",
    "print(f\"\\nğŸ‰ åµŒå…¥å’Œç›¸ä¼¼åº¦è®¡ç®—å®Œæˆï¼\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f572a33b",
   "metadata": {},
   "source": [
    "### ğŸ” æŸ¥çœ‹åµŒå…¥ç»“æœ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0bc8271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“– æŸ¥çœ‹åµŒå…¥æ–‡ä»¶: Embedding_on-surface-synthesis-of.txt\n",
      "==================================================\n",
      "ğŸ“Š åµŒå…¥ç›¸ä¼¼åº¦ç­›é€‰åæ®µè½æ•°: 20\n",
      "\n",
      "ğŸ“„ ç›¸ä¼¼åº¦æœ€é«˜çš„æ®µè½é¢„è§ˆ:\n",
      "------------------------------\n",
      "æ®µè½ 1: Recently, we have established on-surface syntheses of indenoï¬‚uorene polymers by utilizing oxidative cyclization of methyl groups against phenylene rings of polyphenylene backbones,25,26 an alternative...\n",
      "æ®µè½ 3: The observed polymers were no longer packed into islands. This change can be attributed to the desorption of bromine atoms from the Au(111) surface, which is known to be promoted by the presence of at...\n"
     ]
    }
   ],
   "source": [
    "# æŸ¥çœ‹åµŒå…¥ç»“æœ\n",
    "sample_embedding = embedding_files[0]\n",
    "print(f\"ğŸ“– æŸ¥çœ‹åµŒå…¥æ–‡ä»¶: {os.path.basename(sample_embedding)}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "with open(sample_embedding, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "print(f\"ğŸ“Š åµŒå…¥ç›¸ä¼¼åº¦ç­›é€‰åæ®µè½æ•°: {len(lines)}\")\n",
    "print(\"\\nğŸ“„ ç›¸ä¼¼åº¦æœ€é«˜çš„æ®µè½é¢„è§ˆ:\")\n",
    "print(\"-\" * 30)\n",
    "for i, line in enumerate(lines[:3]):\n",
    "    if line.strip():\n",
    "        print(f\"æ®µè½ {i+1}: {line[:200]}...\" if len(line) > 200 else f\"æ®µè½ {i+1}: {line}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4860a8f4",
   "metadata": {},
   "source": [
    "## ğŸ¤– æ­¥éª¤ 4: LLMå†…å®¹è¿‡æ»¤\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9af29236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ æ­¥éª¤ 4/5: LLMå†…å®¹è¿‡æ»¤...\n",
      "==================================================\n",
      "\n",
      "ğŸ“„ å¤„ç†æ–‡ä»¶ 1/1: Embedding_on-surface-synthesis-of.txt\n",
      "ğŸ” å¤„ç†æ–‡ä»¶: Embedding_on-surface-synthesis-of.txt\n",
      "==================================================\n",
      "ğŸ“Š åŸå§‹æ®µè½æ•°: 10\n",
      "\n",
      "ğŸ¤– æ­¥éª¤1: LLMå†…å®¹è¿‡æ»¤...\n",
      "ğŸ” å°è¯•åŠ è½½æ¨¡å‹ï¼Œè·¯å¾„: /Users/zhaowenyuan/Projects/FCPDExtractor/models\n",
      "âœ… æˆåŠŸåŠ è½½ nous-hermes-llama2-13b.Q4_0.gguf æ¨¡å‹\n",
      "âœ… è¿‡æ»¤åæ®µè½æ•°: 4\n",
      "  âœ… LLMå†…å®¹è¿‡æ»¤å®Œæˆ\n",
      "  ğŸ“ è¾“å‡ºæ–‡ä»¶: /Users/zhaowenyuan/Projects/FCPDExtractor/Data/output/on-surface-synthesis-of/Embedding_on-surface-synthesis-of_Filtered.txt\n",
      "\n",
      "ğŸ‰ LLMå†…å®¹è¿‡æ»¤å®Œæˆï¼\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸš€ æ­¥éª¤ 4/5: LLMå†…å®¹è¿‡æ»¤...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "filter_files = []\n",
    "\n",
    "for i, embedding_file in enumerate(embedding_files, 1):\n",
    "    print(f\"\\nğŸ“„ å¤„ç†æ–‡ä»¶ {i}/{len(embedding_files)}: {os.path.basename(embedding_file)}\")\n",
    "    \n",
    "    # æ‰§è¡ŒLLMå†…å®¹è¿‡æ»¤\n",
    "    filter_file_path = process_text_file_for_filter_meta_llama(embedding_file)\n",
    "    filter_files.append(filter_file_path)\n",
    "    \n",
    "    print(f\"  âœ… LLMå†…å®¹è¿‡æ»¤å®Œæˆ\")\n",
    "    print(f\"  ğŸ“ è¾“å‡ºæ–‡ä»¶: {filter_file_path}\")\n",
    "\n",
    "print(f\"\\nğŸ‰ LLMå†…å®¹è¿‡æ»¤å®Œæˆï¼\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4522a3d6",
   "metadata": {},
   "source": [
    "### ğŸ” æŸ¥çœ‹LLMè¿‡æ»¤ç»“æœ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4def142c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“– æŸ¥çœ‹è¿‡æ»¤æ–‡ä»¶: Embedding_on-surface-synthesis-of_Filtered.txt\n",
      "==================================================\n",
      "ğŸ“Š LLMè¿‡æ»¤åæ®µè½æ•°: 8\n",
      "\n",
      "ğŸ“„ è¿‡æ»¤åçš„æ®µè½é¢„è§ˆ:\n",
      "------------------------------\n",
      "æ®µè½ 1: Recently, we have established on-surface syntheses of indenoï¬‚uorene polymers by utilizing oxidative cyclization of methyl groups against phenylene rings of polyphenylene backbones,25,26 an alternative...\n",
      "æ®µè½ 3: The observed polymers were no longer packed into islands. This change can be attributed to the desorption of bromine atoms from the Au(111) surface, which is known to be promoted by the presence of at...\n"
     ]
    }
   ],
   "source": [
    "# æŸ¥çœ‹LLMè¿‡æ»¤ç»“æœ\n",
    "sample_filter = filter_files[0]\n",
    "print(f\"ğŸ“– æŸ¥çœ‹è¿‡æ»¤æ–‡ä»¶: {os.path.basename(sample_filter)}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "with open(sample_filter, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "print(f\"ğŸ“Š LLMè¿‡æ»¤åæ®µè½æ•°: {len(lines)}\")\n",
    "print(\"\\nğŸ“„ è¿‡æ»¤åçš„æ®µè½é¢„è§ˆ:\")\n",
    "print(\"-\" * 30)\n",
    "for i, line in enumerate(lines[:3]):\n",
    "    if line.strip():\n",
    "        print(f\"æ®µè½ {i+1}: {line[:200]}...\" if len(line) > 200 else f\"æ®µè½ {i+1}: {line}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88626257",
   "metadata": {},
   "source": [
    "## ğŸ“Š æ­¥éª¤ 5: æŠ½è±¡å’Œæ€»ç»“\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a11b502a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ æ­¥éª¤ 5/5: æŠ½è±¡å’Œæ€»ç»“...\n",
      "==================================================\n",
      "\n",
      "ğŸ“„ å¤„ç†æ–‡ä»¶ 1/1: Embedding_on-surface-synthesis-of_Filtered.txt\n",
      "ğŸ” å¤„ç†æ–‡ä»¶: Embedding_on-surface-synthesis-of_Filtered.txt\n",
      "==================================================\n",
      "ğŸ“Š åŸå§‹æ®µè½æ•°: 4\n",
      "\n",
      "ğŸ“ æ­¥éª¤2: æ–‡æœ¬æŠ½è±¡...\n",
      "ğŸ” å°è¯•åŠ è½½æ¨¡å‹ï¼Œè·¯å¾„: /Users/zhaowenyuan/Projects/FCPDExtractor/models\n",
      "âœ… æˆåŠŸåŠ è½½ nous-hermes-llama2-13b.Q4_0.gguf æ¨¡å‹\n",
      "Abstract 1/4:\n",
      " The resulting para-type oligo(indenoindene) (p-OInIn, 4) was characterized by means of low-temperature STM/STS and noncontact atomic force microscopy (nc-AFM). On the basis of our previous study on dihydroindenofluorene (DHIN),28 we propose that this reaction sequence is also applicable to other molecular systems with different substituents or structural features. In conclusion, these results provide an experimental demonstration for on-surface synthesis of para-type oligo(indenoindene) by thermally activated reactions, and offer a novel approach towards the precise control of molecular structures in surface chemistry. 24 POLYMERS ACCEPTED MANUSCRIPT\n",
      "Abstract 2/4:\n",
      "\n",
      "In this study, we have investigated various chemical reactions that occur at a temperature of 180 Â°C for Au(111) surfaces functionalized with bromine atoms. These reactions include desorption processes where hydrogen is present and oxidative cyclization of methyl groups on the polymer backbones.\n",
      "Abstract 3/4:\n",
      "Reaction Pathway from 1 to p-OInIn 4 on Au(111)\n",
      "Abstract 4/4:\n",
      "\n",
      " The experimental approach employed to investigate the adsorption and activation of CLP precursor molecules involved low-energy electron diffraction (LEED), scanning tunneling microscopy (STM), X-ray photoelectron spectroscopy (XPS) and density functional theory calculations (DFT).\n",
      "  âœ… æŠ½è±¡å®Œæˆ: /Users/zhaowenyuan/Projects/FCPDExtractor/Data/output/on-surface-synthesis-of/Embedding_on-surface-synthesis-of_Filtered_Abstract.txt\n",
      "ğŸ” å¤„ç†æ–‡ä»¶: Embedding_on-surface-synthesis-of_Filtered.txt\n",
      "==================================================\n",
      "ğŸ“Š åŸå§‹æ®µè½æ•°: 4\n",
      "\n",
      "ğŸ“Š æ­¥éª¤3: å‚æ•°æ€»ç»“...\n",
      "ğŸ” å°è¯•åŠ è½½æ¨¡å‹ï¼Œè·¯å¾„: /Users/zhaowenyuan/Projects/FCPDExtractor/models\n",
      "âœ… æˆåŠŸåŠ è½½ nous-hermes-llama2-13b.Q4_0.gguf æ¨¡å‹\n",
      "Summarized 1/4:\n",
      " -------------------------------- | ----------| -----------| --------| -----------| --------------- | dibromo-trimethyl-p-terphenyl (1)| Au(111)     | N/A         | p-OInIn 4| oligoindigoindene | monolayer, extended\n",
      "Summarized 2/4:\n",
      "\n",
      "Precursor   | Azobenzene-4-carboxylic acid N-hydroxysuccinimide ester | Au(111) surface | N/A          | N/A           | N/A           |\n",
      "Substrate  |                                |               |             |              |             |\n",
      "Temperature| N/A                            | 360 Â°C         | Oxidative cyclization products (e.g., azobenzene-4,4'-diyl bis(2-hydroxyethyl)succinate radicals) | 1D          |\n",
      "Product    | Azobenzene-4,4'-diyl bis(2-hydroxyethyl)succinate radicals                           |               |             |              | N/A           |\n",
      "Dimensions| 1D (azobenzene backbone)     |               |             |              | 1D          |\n",
      "Summarized 3/4:\n",
      " AU(111) - 4f - InCl + H2 + Heat 298K N/A OInInN+N-OInIn, (p-OH)(2+)-N-OInIn ClO3-, NH3 |\n",
      "Summarized 4/4:\n",
      "\n",
      "Precursor    substrate      temperature     product                             dimensions\n",
      "1               Au(111)       RT                         Oligo-p-phenylene (2,3,4...)  Ladder Polymer (3D)\n",
      "  âœ… æ€»ç»“å®Œæˆ: /Users/zhaowenyuan/Projects/FCPDExtractor/Data/output/on-surface-synthesis-of/Embedding_on-surface-synthesis-of_Filtered_Summarized.txt\n",
      "\n",
      "ğŸ‰ æŠ½è±¡å’Œæ€»ç»“å®Œæˆï¼\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸš€ æ­¥éª¤ 5/5: æŠ½è±¡å’Œæ€»ç»“...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "abstract_files = []\n",
    "summarized_files = []\n",
    "\n",
    "# ä½¿ç”¨è¿‡æ»¤åçš„æ–‡ä»¶è¿›è¡ŒæŠ½è±¡å’Œæ€»ç»“\n",
    "for i, filter_file in enumerate(filter_files, 1):\n",
    "    print(f\"\\nğŸ“„ å¤„ç†æ–‡ä»¶ {i}/{len(filter_files)}: {os.path.basename(filter_file)}\")\n",
    "    \n",
    "    # æ‰§è¡ŒæŠ½è±¡\n",
    "    abstract_file_path = process_text_file_for_abstract_meta_llama(filter_file)\n",
    "    abstract_files.append(abstract_file_path)\n",
    "    print(f\"  âœ… æŠ½è±¡å®Œæˆ: {abstract_file_path}\")\n",
    "    \n",
    "    # æ‰§è¡Œæ€»ç»“\n",
    "    summerized_file_path = process_text_file_for_summerized_meta_llama(filter_file)\n",
    "    summarized_files.append(summerized_file_path)\n",
    "    print(f\"  âœ… æ€»ç»“å®Œæˆ: {summerized_file_path}\")\n",
    "\n",
    "print(f\"\\nğŸ‰ æŠ½è±¡å’Œæ€»ç»“å®Œæˆï¼\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dceb377e",
   "metadata": {},
   "source": [
    "### ğŸ” æŸ¥çœ‹æœ€ç»ˆç»“æœ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "38340a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“– æŸ¥çœ‹æœ€ç»ˆæ€»ç»“: Embedding_on-surface-synthesis-of_Filtered_Summarized.txt\n",
      "==================================================\n",
      "ğŸ“Š æ€»ç»“å†…å®¹é•¿åº¦: 1192 å­—ç¬¦\n",
      "\n",
      "ğŸ“„ æ€»ç»“å†…å®¹é¢„è§ˆ:\n",
      "------------------------------\n",
      " -------------------------------- | ----------| -----------| --------| -----------| --------------- | dibromo-trimethyl-p-terphenyl (1)| Au(111)     | N/A         | p-OInIn 4| oligoindigoindene | monolayer, extended\n",
      "\n",
      "\n",
      "Precursor   | Azobenzene-4-carboxylic acid N-hydroxysuccinimide ester | Au(111) surface | N/A          | N/A           | N/A           |\n",
      "Substrate  |                                |               |             |              |             |\n",
      "Temperature| N/A                            | 360 Â°C         | Oxidative cyclization products (e.g., azobenzene-4,4'-diyl bis(2-hydroxyethyl)succinate radicals) | 1D          |\n",
      "Product    | Azobenzene-4,4'-diyl bis(2-hydroxyethyl)succinate radicals                           |               |             |              | N/A           |\n",
      "Dimensions| 1D (azobenzene backbone)     |               |             |              | 1D          |\n",
      "\n",
      " AU(111) - 4f - InCl + H2 + Heat 298K N/A OInInN+N-OInIn, (p-OH)(2+)-N-OInIn ClO3-, NH3 |\n",
      "\n",
      "\n",
      "Precurs...\n"
     ]
    }
   ],
   "source": [
    "# æŸ¥çœ‹æœ€ç»ˆæ€»ç»“ç»“æœ\n",
    "sample_summarized = summarized_files[0]\n",
    "print(f\"ğŸ“– æŸ¥çœ‹æœ€ç»ˆæ€»ç»“: {os.path.basename(sample_summarized)}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "with open(sample_summarized, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "    content = f.read()\n",
    "    \n",
    "print(f\"ğŸ“Š æ€»ç»“å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦\")\n",
    "print(\"\\nğŸ“„ æ€»ç»“å†…å®¹é¢„è§ˆ:\")\n",
    "print(\"-\" * 30)\n",
    "print(content[:1000] + \"...\" if len(content) > 1000 else content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47901c5c",
   "metadata": {},
   "source": [
    "## ğŸ“Š å¤„ç†ç»“æœç»Ÿè®¡\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9a0cd50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š OSSExtractor å¤„ç†ç»“æœç»Ÿè®¡\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>æ–‡ä»¶</th>\n",
       "      <th>åŸå§‹PDF (MB)</th>\n",
       "      <th>é¢„å¤„ç† (KB)</th>\n",
       "      <th>åµŒå…¥ç­›é€‰ (KB)</th>\n",
       "      <th>LLMè¿‡æ»¤ (KB)</th>\n",
       "      <th>æœ€ç»ˆæ€»ç»“ (KB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>on-surface-synthesis-of.txt</td>\n",
       "      <td>0.02</td>\n",
       "      <td>14.91</td>\n",
       "      <td>7.58</td>\n",
       "      <td>3.16</td>\n",
       "      <td>1.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            æ–‡ä»¶  åŸå§‹PDF (MB)  é¢„å¤„ç† (KB)  åµŒå…¥ç­›é€‰ (KB)  LLMè¿‡æ»¤ (KB)  \\\n",
       "0  on-surface-synthesis-of.txt        0.02     14.91       7.58        3.16   \n",
       "\n",
       "   æœ€ç»ˆæ€»ç»“ (KB)  \n",
       "0       1.17  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ‰ æ‰€æœ‰å¤„ç†æ­¥éª¤å®Œæˆï¼\n"
     ]
    }
   ],
   "source": [
    "# ç»Ÿè®¡å¤„ç†ç»“æœ\n",
    "print(\"ğŸ“Š OSSExtractor å¤„ç†ç»“æœç»Ÿè®¡\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "stats = []\n",
    "for i, file_path in enumerate(output_files):\n",
    "    filename = os.path.basename(file_path)\n",
    "    \n",
    "    # ç»Ÿè®¡å„ä¸ªæ­¥éª¤çš„æ–‡ä»¶å¤§å°\n",
    "    original_size = os.path.getsize(file_path) if os.path.exists(file_path) else 0\n",
    "    \n",
    "    processed_file = processed_files[i] if i < len(processed_files) else None\n",
    "    processed_size = os.path.getsize(processed_file) if processed_file and os.path.exists(processed_file) else 0\n",
    "    \n",
    "    embedding_file = embedding_files[i] if i < len(embedding_files) else None\n",
    "    embedding_size = os.path.getsize(embedding_file) if embedding_file and os.path.exists(embedding_file) else 0\n",
    "    \n",
    "    filter_file = filter_files[i] if i < len(filter_files) else None\n",
    "    filter_size = os.path.getsize(filter_file) if filter_file and os.path.exists(filter_file) else 0\n",
    "    \n",
    "    summarized_file = summarized_files[i] if i < len(summarized_files) else None\n",
    "    summarized_size = os.path.getsize(summarized_file) if summarized_file and os.path.exists(summarized_file) else 0\n",
    "    \n",
    "    stats.append({\n",
    "        'æ–‡ä»¶': filename,\n",
    "        'åŸå§‹PDF (MB)': round(original_size / 1024 / 1024, 2),\n",
    "        'é¢„å¤„ç† (KB)': round(processed_size / 1024, 2),\n",
    "        'åµŒå…¥ç­›é€‰ (KB)': round(embedding_size / 1024, 2),\n",
    "        'LLMè¿‡æ»¤ (KB)': round(filter_size / 1024, 2),\n",
    "        'æœ€ç»ˆæ€»ç»“ (KB)': round(summarized_size / 1024, 2)\n",
    "    })\n",
    "\n",
    "# æ˜¾ç¤ºç»Ÿè®¡è¡¨æ ¼\n",
    "df_stats = pd.DataFrame(stats)\n",
    "display(df_stats)\n",
    "\n",
    "print(\"\\nğŸ‰ æ‰€æœ‰å¤„ç†æ­¥éª¤å®Œæˆï¼\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147de13a",
   "metadata": {},
   "source": [
    "## ğŸ”§ è°ƒè¯•å’Œä¼˜åŒ–å»ºè®®\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9d08b082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ è°ƒè¯•å’Œä¼˜åŒ–å»ºè®®\n",
      "==================================================\n",
      "\n",
      "1. ğŸ“Š æ£€æŸ¥åµŒå…¥ç›¸ä¼¼åº¦é˜ˆå€¼\n",
      "   - å¦‚æœç­›é€‰çš„æ®µè½å¤ªå°‘ï¼Œå¯ä»¥é™ä½ç›¸ä¼¼åº¦é˜ˆå€¼\n",
      "   - å¦‚æœç­›é€‰çš„æ®µè½å¤ªå¤šï¼Œå¯ä»¥æé«˜ç›¸ä¼¼åº¦é˜ˆå€¼\n",
      "\n",
      "2. ğŸ¤– ä¼˜åŒ–LLMæç¤ºè¯\n",
      "   - åœ¨Filter.pyä¸­è°ƒæ•´é—®é¢˜æè¿°\n",
      "   - åœ¨Summerized.pyä¸­è°ƒæ•´å‚æ•°æå–æç¤ºè¯\n",
      "\n",
      "3. ğŸ“ è°ƒæ•´æ–‡æœ¬é¢„å¤„ç†\n",
      "   - åœ¨TXT_Processing.pyä¸­ä¿®æ”¹è¿‡æ»¤è§„åˆ™\n",
      "   - è°ƒæ•´æ®µè½åˆ†å‰²ç­–ç•¥\n",
      "\n",
      "4. ğŸ” æ£€æŸ¥æ¨¡å‹æ€§èƒ½\n",
      "   - è§‚å¯ŸLLMçš„å“åº”è´¨é‡\n",
      "   - è€ƒè™‘è°ƒæ•´æ¨¡å‹å‚æ•°ï¼ˆtemp, top_pç­‰ï¼‰\n",
      "\n",
      "5. ğŸ“ˆ å¯è§†åŒ–å¤„ç†æµç¨‹\n",
      "   - ç»˜åˆ¶å„æ­¥éª¤çš„æ•°æ®é‡å˜åŒ–\n",
      "   - åˆ†æå¤„ç†æ•ˆç‡\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ”§ è°ƒè¯•å’Œä¼˜åŒ–å»ºè®®\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\"\"\n",
    "1. ğŸ“Š æ£€æŸ¥åµŒå…¥ç›¸ä¼¼åº¦é˜ˆå€¼\n",
    "   - å¦‚æœç­›é€‰çš„æ®µè½å¤ªå°‘ï¼Œå¯ä»¥é™ä½ç›¸ä¼¼åº¦é˜ˆå€¼\n",
    "   - å¦‚æœç­›é€‰çš„æ®µè½å¤ªå¤šï¼Œå¯ä»¥æé«˜ç›¸ä¼¼åº¦é˜ˆå€¼\n",
    "\n",
    "2. ğŸ¤– ä¼˜åŒ–LLMæç¤ºè¯\n",
    "   - åœ¨Filter.pyä¸­è°ƒæ•´é—®é¢˜æè¿°\n",
    "   - åœ¨Summerized.pyä¸­è°ƒæ•´å‚æ•°æå–æç¤ºè¯\n",
    "\n",
    "3. ğŸ“ è°ƒæ•´æ–‡æœ¬é¢„å¤„ç†\n",
    "   - åœ¨TXT_Processing.pyä¸­ä¿®æ”¹è¿‡æ»¤è§„åˆ™\n",
    "   - è°ƒæ•´æ®µè½åˆ†å‰²ç­–ç•¥\n",
    "\n",
    "4. ğŸ” æ£€æŸ¥æ¨¡å‹æ€§èƒ½\n",
    "   - è§‚å¯ŸLLMçš„å“åº”è´¨é‡\n",
    "   - è€ƒè™‘è°ƒæ•´æ¨¡å‹å‚æ•°ï¼ˆtemp, top_pç­‰ï¼‰\n",
    "\n",
    "5. ğŸ“ˆ å¯è§†åŒ–å¤„ç†æµç¨‹\n",
    "   - ç»˜åˆ¶å„æ­¥éª¤çš„æ•°æ®é‡å˜åŒ–\n",
    "   - åˆ†æå¤„ç†æ•ˆç‡\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3912b46",
   "metadata": {},
   "source": [
    "## ğŸ“Š ç»“æœæŸ¥çœ‹å’Œåˆ†æ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6b00104c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š æŸ¥çœ‹å¤„ç†ç»“æœ...\n",
      "==================================================\n",
      "\n",
      "ğŸ“ åŸå§‹æ–‡æœ¬:\n",
      "  1. on-surface-synthesis-of.txt (533 è¡Œ)\n",
      "\n",
      "ğŸ“ é¢„å¤„ç†æ–‡æœ¬:\n",
      "  1. Processed_on-surface-synthesis-of.txt (38 è¡Œ)\n",
      "\n",
      "ğŸ“ åµŒå…¥æ–‡ä»¶:\n",
      "  1. Embedding_on-surface-synthesis-of.txt (20 è¡Œ)\n",
      "\n",
      "ğŸ“ è¿‡æ»¤æ–‡ä»¶:\n",
      "  1. Embedding_on-surface-synthesis-of_Filtered.txt (8 è¡Œ)\n",
      "\n",
      "ğŸ“ æŠ½è±¡æ–‡ä»¶:\n",
      "  1. Embedding_on-surface-synthesis-of_Filtered_Abstract.txt (10 è¡Œ)\n",
      "\n",
      "ğŸ“ æ€»ç»“æ–‡ä»¶:\n",
      "  1. Embedding_on-surface-synthesis-of_Filtered_Summarized.txt (15 è¡Œ)\n",
      "\n",
      "ğŸ‰ å¤„ç†å®Œæˆï¼å…±å¤„ç†äº† 1 ä¸ªPDFæ–‡ä»¶\n"
     ]
    }
   ],
   "source": [
    "# æŸ¥çœ‹æœ€ç»ˆç»“æœ\n",
    "print(\"ğŸ“Š æŸ¥çœ‹å¤„ç†ç»“æœ...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# æ˜¾ç¤ºæ‰€æœ‰ç”Ÿæˆçš„æ–‡ä»¶\n",
    "all_files = {\n",
    "    'åŸå§‹æ–‡æœ¬': output_files,\n",
    "    'é¢„å¤„ç†æ–‡æœ¬': processed_files,\n",
    "    'åµŒå…¥æ–‡ä»¶': embedding_files,\n",
    "    'è¿‡æ»¤æ–‡ä»¶': filter_files,\n",
    "    'æŠ½è±¡æ–‡ä»¶': abstract_files,\n",
    "    'æ€»ç»“æ–‡ä»¶': summarized_files\n",
    "}\n",
    "\n",
    "for category, files in all_files.items():\n",
    "    print(f\"\\nğŸ“ {category}:\")\n",
    "    for i, file in enumerate(files, 1):\n",
    "        if os.path.exists(file):\n",
    "            with open(file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                lines = f.readlines()\n",
    "            print(f\"  {i}. {os.path.basename(file)} ({len(lines)} è¡Œ)\")\n",
    "        else:\n",
    "            print(f\"  {i}. {os.path.basename(file)} (æ–‡ä»¶ä¸å­˜åœ¨)\")\n",
    "\n",
    "print(f\"\\nğŸ‰ å¤„ç†å®Œæˆï¼å…±å¤„ç†äº† {len(pdf_files)} ä¸ªPDFæ–‡ä»¶\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b6f7ab",
   "metadata": {},
   "source": [
    "## ğŸ” ç»“æœåˆ†æ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e65ff5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” åˆ†ææœ€ç»ˆç»“æœ...\n",
      "==================================================\n",
      "ğŸ“„ æœ€ç»ˆæ€»ç»“ç»“æœ:\n",
      "\n",
      "æ–‡ä»¶ 1: Embedding_on-surface-synthesis-of_Filtered_Summarized.txt\n",
      "å†…å®¹é¢„è§ˆ:\n",
      "------------------------------\n",
      " -------------------------------- | ----------| -----------| --------| -----------| --------------- | dibromo-trimethyl-p-terphenyl (1)| Au(111)     | N/A         | p-OInIn 4| oligoindigoindene | monolayer, extended\n",
      "\n",
      "\n",
      "Precursor   | Azobenzene-4-carboxylic acid N-hydroxysuccinimide ester | Au(111) surface | N/A          | N/A           | N/A           |\n",
      "Substrate  |                                |               |             |              |             |\n",
      "Temperature| N/A                        ...\n"
     ]
    }
   ],
   "source": [
    "# åˆ†ææœ€ç»ˆç»“æœ\n",
    "print(\"ğŸ” åˆ†ææœ€ç»ˆç»“æœ...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# æŸ¥çœ‹æ€»ç»“æ–‡ä»¶çš„å†…å®¹\n",
    "if summarized_files:\n",
    "    print(\"ğŸ“„ æœ€ç»ˆæ€»ç»“ç»“æœ:\")\n",
    "    for i, file in enumerate(summarized_files, 1):\n",
    "        print(f\"\\næ–‡ä»¶ {i}: {os.path.basename(file)}\")\n",
    "        if os.path.exists(file):\n",
    "            with open(file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                content = f.read()\n",
    "            print(\"å†…å®¹é¢„è§ˆ:\")\n",
    "            print(\"-\" * 30)\n",
    "            print(content[:500] + \"...\" if len(content) > 500 else content)\n",
    "        else:\n",
    "            print(\"æ–‡ä»¶ä¸å­˜åœ¨\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "712c2321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š å¤„ç†ç»Ÿè®¡ä¿¡æ¯:\n",
      "==============================\n",
      "æ–‡ä»¶ 1: 38 â†’ 8 æ®µè½ (ä¿ç•™ç‡: 21.1%)\n",
      "\n",
      "æ€»è®¡: 38 â†’ 8 æ®µè½\n",
      "æ•´ä½“ä¿ç•™ç‡: 21.1%\n",
      "\n",
      "ğŸ‰ æ‘˜è¦ç»“è®ºä¸“ç”¨å¤„ç†å®Œæˆï¼\n"
     ]
    }
   ],
   "source": [
    "# æ˜¾ç¤ºå¤„ç†ç»Ÿè®¡ä¿¡æ¯\n",
    "print(\"\\nğŸ“Š å¤„ç†ç»Ÿè®¡ä¿¡æ¯:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "total_paragraphs_original = 0\n",
    "total_paragraphs_filtered = 0\n",
    "\n",
    "for i, (original, filtered) in enumerate(zip(processed_files, filter_files), 1):\n",
    "    if os.path.exists(original):\n",
    "        with open(original, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            original_lines = len(f.readlines())\n",
    "        total_paragraphs_original += original_lines\n",
    "    \n",
    "    if os.path.exists(filtered):\n",
    "        with open(filtered, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            filtered_lines = len(f.readlines())\n",
    "        total_paragraphs_filtered += filtered_lines\n",
    "        \n",
    "        print(f\"æ–‡ä»¶ {i}: {original_lines} â†’ {filtered_lines} æ®µè½ (ä¿ç•™ç‡: {filtered_lines/original_lines*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\næ€»è®¡: {total_paragraphs_original} â†’ {total_paragraphs_filtered} æ®µè½\")\n",
    "print(f\"æ•´ä½“ä¿ç•™ç‡: {total_paragraphs_filtered/total_paragraphs_original*100:.1f}%\")\n",
    "\n",
    "print(f\"\\nğŸ‰ æ‘˜è¦ç»“è®ºä¸“ç”¨å¤„ç†å®Œæˆï¼\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ossextractor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
