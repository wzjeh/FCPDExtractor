import pandas as pd
import os
import sys
sys.path.append('Text Parser')
sys.path.append('Text Extraction')
from PDF_Unified_Processor import save_contents_to_specific_folders
from TXT_Processing import process_text_file_for_processing
from Embedding_and_Similarity import process_text_file_for_embedding
from Unified_Text_Processor import (
    process_text_file_for_filter, process_text_file_for_abstract, process_text_file_for_summerized,
    process_text_file_for_filter, process_text_file_for_abstract, 
    process_text_file_for_summerized
)

print("ğŸš€ å¯åŠ¨ OSSExtractor è¡¨é¢åˆæˆå‚æ•°æå–å·¥å…·")
print("=" * 60)

pdf_files = [
"/Users/zhaowenyuan/Projects/FCPDExtractor/Data/papers/101021acsoprd7b00291.pdf"
]
base_output_dir = '/Users/zhaowenyuan/Projects/FCPDExtractor/Data'  

print("ğŸ“„ æ­¥éª¤ 1/5: PDFè½¬æ–‡æœ¬å¤„ç†...")
output_files = save_contents_to_specific_folders(pdf_files, base_output_dir)
print("âœ… PDFè½¬æ–‡æœ¬å®Œæˆ")

print("\nğŸ“ æ­¥éª¤ 2/5: æ–‡æœ¬é¢„å¤„ç†...")
processed_files = []
total_filtered_count = 0
for file_path in output_files:
    print(f"å¤„ç†æ–‡ä»¶: {os.path.basename(file_path)}")
    processed_file_path, filtered_count = process_text_file_for_processing(file_path)
    processed_files.append(processed_file_path)
    total_filtered_count += filtered_count
print(f"âœ… æ–‡æœ¬é¢„å¤„ç†å®Œæˆï¼Œè¿‡æ»¤äº† {total_filtered_count} ä¸ªæ®µè½")

print("\nğŸ” æ­¥éª¤ 3/5: åµŒå…¥å’Œç›¸ä¼¼åº¦è®¡ç®—...")
embedding_files = []
for file_path in processed_files:
    print(f"å¤„ç†æ–‡ä»¶: {os.path.basename(file_path)}")
    embedding_file_path = process_text_file_for_embedding(file_path)
    embedding_files.append(embedding_file_path)
print("âœ… åµŒå…¥å’Œç›¸ä¼¼åº¦è®¡ç®—å®Œæˆ")

print("\nğŸ¤– æ­¥éª¤ 4/5: LLMå†…å®¹è¿‡æ»¤...")
print("ğŸ’¡ ä½¿ç”¨nous-hermes-llama2-13bæ¨¡å‹è¿›è¡Œæ™ºèƒ½è¿‡æ»¤")
filter_files = []
for file_path in embedding_files:
    print(f"å¤„ç†æ–‡ä»¶: {os.path.basename(file_path)}")
    filter_file_path = process_text_file_for_filter(file_path)
    filter_files.append(filter_file_path)
print("âœ… LLMå†…å®¹è¿‡æ»¤å®Œæˆ")

print("\nğŸ“Š æ­¥éª¤ 5/5: æŠ½è±¡å’Œæ€»ç»“...")
print("ğŸ’¡ ä½¿ç”¨nous-hermes-llama2-13bæ¨¡å‹è¿›è¡ŒæŠ½è±¡å’Œæ€»ç»“")
abstract_files = []
summarized_files = []
for file_path in filter_files:
    print(f"å¤„ç†æ–‡ä»¶: {os.path.basename(file_path)}")
    abstract_file_path = process_text_file_for_abstract(file_path)
    summerized_file_path = process_text_file_for_summerized(file_path)
    abstract_files.append(abstract_file_path)
    summarized_files.append(summerized_file_path)
print("âœ… æŠ½è±¡å’Œæ€»ç»“å®Œæˆ")

print("\nğŸ‰ æ‰€æœ‰å¤„ç†æ­¥éª¤å®Œæˆï¼")
print("=" * 60)

# æ˜¾ç¤ºæœ€ç»ˆç»“æœ
print("\nğŸ“Š å¤„ç†ç»“æœæ€»ç»“:")
print("=" * 30)
print(f"ğŸ“ åŸå§‹æ–‡æœ¬æ–‡ä»¶: {len(output_files)} ä¸ª")
print(f"ğŸ“ é¢„å¤„ç†æ–‡ä»¶: {len(processed_files)} ä¸ª")
print(f"ğŸ“ åµŒå…¥æ–‡ä»¶: {len(embedding_files)} ä¸ª")
print(f"ğŸ“ è¿‡æ»¤æ–‡ä»¶: {len(filter_files)} ä¸ª")
print(f"ğŸ“ æŠ½è±¡æ–‡ä»¶: {len(abstract_files)} ä¸ª")
print(f"ğŸ“ æ€»ç»“æ–‡ä»¶: {len(summarized_files)} ä¸ª")

print(f"\nğŸ¯ æœ€ç»ˆè¾“å‡ºæ–‡ä»¶:")
for i, file in enumerate(summarized_files, 1):
    if os.path.exists(file):
        with open(file, 'r', encoding='utf-8', errors='ignore') as f:
            lines = f.readlines()
        print(f"  {i}. {os.path.basename(file)} ({len(lines)} è¡Œ)")
    else:
        print(f"  {i}. {os.path.basename(file)} (æ–‡ä»¶ä¸å­˜åœ¨)")

print(f"\nâœ… å¤„ç†å®Œæˆï¼å…±å¤„ç†äº† {len(pdf_files)} ä¸ªPDFæ–‡ä»¶")



